[
  {
    "objectID": "supplemental/S2_its.html",
    "href": "supplemental/S2_its.html",
    "title": "Individual Tree Detection & Segmentation",
    "section": "",
    "text": "Code\nlidRbook section"
  },
  {
    "objectID": "supplemental/S2_its.html#relevant-resources",
    "href": "supplemental/S2_its.html#relevant-resources",
    "title": "Individual Tree Detection & Segmentation",
    "section": "",
    "text": "Code\nlidRbook section"
  },
  {
    "objectID": "supplemental/S2_its.html#overview",
    "href": "supplemental/S2_its.html#overview",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Overview",
    "text": "Overview\nThis code demonstrates individual tree segmentation (ITS) using LiDAR data. It covers CHM-based and point cloud-based methods for tree detection and segmentation. The code also shows how to extract metrics at the tree level and visualize them."
  },
  {
    "objectID": "supplemental/S2_its.html#environment",
    "href": "supplemental/S2_its.html#environment",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Environment",
    "text": "Environment\n\n# Clear environment\nrm(list = ls(globalenv()))\n\n# *Ensure 'concaveman' is installed for tree segmentation*\nif (!requireNamespace(\"concaveman\", quietly = TRUE)) {\n  install.packages(\"concaveman\")\n}\n\n# Load all required packages\nlibrary(concaveman)\nlibrary(lidR)\nlibrary(sf)\nlibrary(terra)\n\n# Read in LiDAR file and set some color palettes\nlas &lt;- readLAS(\"data/zrh_norm.laz\")\ncol &lt;- height.colors(50)\ncol1 &lt;- pastel.colors(900)"
  },
  {
    "objectID": "supplemental/S2_its.html#chm-based-methods",
    "href": "supplemental/S2_its.html#chm-based-methods",
    "title": "Individual Tree Detection & Segmentation",
    "section": "CHM based methods",
    "text": "CHM based methods\nWe start by creating a Canopy Height Model (CHM) from the LiDAR data. The rasterize_canopy() function generates the CHM using a specified resolution (res) and a chosen algorithm, here p2r(0.15), to compute the percentiles.\n\n# Generate CHM\nchm &lt;- rasterize_canopy(las = las, res = 0.5, algorithm = p2r(0.15))\nplot(chm, col = col)\n\n\n\n\n\n\n\n\nAfter building the CHM, we visualize it using a color palette (col)."
  },
  {
    "objectID": "supplemental/S2_its.html#optionally-smooth-the-chm",
    "href": "supplemental/S2_its.html#optionally-smooth-the-chm",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Optionally smooth the CHM",
    "text": "Optionally smooth the CHM\nOptionally, we can smooth the CHM using a kernel to remove small-scale variations and enhance larger features like tree canopies.\n\n# Generate kernel and smooth chm\nkernel &lt;- matrix(1, 3, 3)\nschm &lt;- terra::focal(x = chm, w = kernel, fun = median, na.rm = TRUE)\nplot(schm, col = col)\n\n\n\n\n\n\n\n\nHere, we smooth the CHM using a median filter with a 3x3 kernel. The smoothed CHM (schm) is visualized using a color palette to represent height values."
  },
  {
    "objectID": "supplemental/S2_its.html#tree-detection",
    "href": "supplemental/S2_its.html#tree-detection",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Tree detection",
    "text": "Tree detection\nNext, we detect tree tops using the smoothed CHM. The locate_trees() function identifies tree tops based on local maxima.\n\n# Detect trees\nttops &lt;- locate_trees(las = schm, algorithm = lmf(ws = 2.5))\nttops\n\nSimple feature collection with 2694 features and 2 fields\nAttribute-geometry relationships: constant (2)\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 2670505 ymin: 1258734 xmax: 2670755 ymax: 1258984\nProjected CRS: CH1903+ / LV95\nFirst 10 features:\n   treeID      Z                       geometry\n1       1 37.080 POINT Z (2670514 1258984 37...\n2       2 38.230 POINT Z (2670534 1258984 38...\n3       3 41.185 POINT Z (2670555 1258984 41...\n4       4  3.915 POINT Z (2670578 1258984 3....\n5       5  6.090 POINT Z (2670591 1258984 6.09)\n6       6 37.885 POINT Z (2670597 1258984 37...\n7       7 46.160 POINT Z (2670614 1258984 46...\n8       8 46.645 POINT Z (2670617 1258984 46...\n9       9  9.170 POINT Z (2670652 1258984 9.17)\n10     10  3.075 POINT Z (2670687 1258984 3....\n\nplot(chm, col = col)\nplot(ttops, col = \"black\", add = TRUE, cex = 0.5)\n\n\n\n\n\n\n\n\nThe detected tree tops (ttops) are plotted on top of the CHM (chm) to visualize their positions."
  },
  {
    "objectID": "supplemental/S2_its.html#segmentation",
    "href": "supplemental/S2_its.html#segmentation",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Segmentation",
    "text": "Segmentation\nNow, we perform tree segmentation using the detected tree tops. The segment_trees() function segments the trees in the LiDAR point cloud based on the previously detected tree tops.\n# Segment trees using dalponte\nlas &lt;- segment_trees(las = las, algorithm = dalponte2016(chm = schm, treetops = ttops))\n\n# Count number of trees detected and segmented\nlength(unique(las$treeID) |&gt; na.omit())\n\n[1] 2653\n\n\n# Visualize all trees\nplot(las, color = \"treeID\")\n\n# Select trees by ID\ntree25 &lt;- filter_poi(las = las, treeID == 25)\ntree125 &lt;- filter_poi(las = las, treeID == 125)\n\nplot(tree25, size = 4)\nplot(tree125, size = 3)\nAfter segmentation, we count the number of trees detected and visualize all the trees in the point cloud. We then select two trees (tree25 and tree125) and visualize them individually.\n\n\n\n\n\n\nVariability and testing\n\n\n\nForests are highly variable! This means that some algorithms and parameters will work better than others depending on the data you have. Play around with algorithms and see which works best for your data."
  },
  {
    "objectID": "supplemental/S2_its.html#working-with-rasters",
    "href": "supplemental/S2_its.html#working-with-rasters",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Working with rasters",
    "text": "Working with rasters\nThe lidR package is designed for point clouds, but some functions can be applied to raster data as well. Here, we show how to extract trees from the CHM without using the point cloud directly.\n\n# Generate rasterized delineation\ntrees &lt;- dalponte2016(chm = chm, treetops = ttops)() # Notice the parenthesis at the end\ntrees\n\nclass       : SpatRaster \ndimensions  : 501, 501, 1  (nrow, ncol, nlyr)\nresolution  : 0.5, 0.5  (x, y)\nextent      : 2670505, 2670756, 1258734, 1258985  (xmin, xmax, ymin, ymax)\ncoord. ref. : CH1903+ / LV95 (EPSG:2056) \nsource(s)   : memory\nname        :    Z \nmin value   :    1 \nmax value   : 2694 \n\nplot(trees, col = col1)\nplot(ttops, add = TRUE, cex = 0.5)\n\nWarning in plot.sf(ttops, add = TRUE, cex = 0.5): ignoring all but the first\nattribute\n\n\n\n\n\n\n\n\n\nWe create tree objects (trees) using the dalponte2016 algorithm with the CHM and tree tops. The resulting objects are visualized alongside the detected tree tops."
  },
  {
    "objectID": "supplemental/S2_its.html#tree-detection-1",
    "href": "supplemental/S2_its.html#tree-detection-1",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Tree detection",
    "text": "Tree detection\nWe begin with tree detection using the local maxima filtering (lmf) algorithm. This approach directly works with the LiDAR point cloud to detect tree tops.\n\n# Detect trees\nttops &lt;- locate_trees(las = las, algorithm = lmf(ws = 3, hmin = 5))\n\n# Visualize\nx &lt;- plot(las)\nadd_treetops3d(x = x, ttops = ttops, radius = 0.5)\nWe detect tree tops using the lmf algorithm and visualize them in 3D by adding the tree tops to the LiDAR plot."
  },
  {
    "objectID": "supplemental/S2_its.html#tree-segmentation",
    "href": "supplemental/S2_its.html#tree-segmentation",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Tree segmentation",
    "text": "Tree segmentation\nNext, we perform tree segmentation using the li2012 algorithm, which directly processes the LiDAR point cloud.\n# Segment using li\nlas &lt;- segment_trees(las = las, algorithm = li2012())\n\n\nTree segmentation: 5% (1 threads)\nTree segmentation: 6% (1 threads)\nTree segmentation: 7% (1 threads)\nTree segmentation: 8% (1 threads)\nTree segmentation: 9% (1 threads)\nTree segmentation: 10% (1 threads)\nTree segmentation: 11% (1 threads)\nTree segmentation: 12% (1 threads)\nTree segmentation: 13% (1 threads)\nTree segmentation: 14% (1 threads)\nTree segmentation: 15% (1 threads)\nTree segmentation: 16% (1 threads)\nTree segmentation: 17% (1 threads)\nTree segmentation: 18% (1 threads)\nTree segmentation: 19% (1 threads)\nTree segmentation: 20% (1 threads)\nTree segmentation: 21% (1 threads)\nTree segmentation: 22% (1 threads)\nTree segmentation: 23% (1 threads)\nTree segmentation: 24% (1 threads)\nTree segmentation: 25% (1 threads)\nTree segmentation: 26% (1 threads)\nTree segmentation: 27% (1 threads)\nTree segmentation: 28% (1 threads)\nTree segmentation: 29% (1 threads)\nTree segmentation: 30% (1 threads)\nTree segmentation: 31% (1 threads)\nTree segmentation: 32% (1 threads)\nTree segmentation: 33% (1 threads)\nTree segmentation: 34% (1 threads)\nTree segmentation: 35% (1 threads)\nTree segmentation: 36% (1 threads)\nTree segmentation: 37% (1 threads)\nTree segmentation: 38% (1 threads)\nTree segmentation: 39% (1 threads)\nTree segmentation: 40% (1 threads)\nTree segmentation: 41% (1 threads)\nTree segmentation: 42% (1 threads)\nTree segmentation: 43% (1 threads)\nTree segmentation: 44% (1 threads)\nTree segmentation: 45% (1 threads)\nTree segmentation: 46% (1 threads)\nTree segmentation: 47% (1 threads)\nTree segmentation: 48% (1 threads)\nTree segmentation: 49% (1 threads)\nTree segmentation: 50% (1 threads)\nTree segmentation: 51% (1 threads)\nTree segmentation: 52% (1 threads)\nTree segmentation: 53% (1 threads)\nTree segmentation: 54% (1 threads)\nTree segmentation: 55% (1 threads)\nTree segmentation: 56% (1 threads)\nTree segmentation: 57% (1 threads)\nTree segmentation: 58% (1 threads)\nTree segmentation: 59% (1 threads)\nTree segmentation: 60% (1 threads)\nTree segmentation: 61% (1 threads)\nTree segmentation: 62% (1 threads)\nTree segmentation: 63% (1 threads)\nTree segmentation: 64% (1 threads)\nTree segmentation: 65% (1 threads)\nTree segmentation: 66% (1 threads)\nTree segmentation: 67% (1 threads)\nTree segmentation: 68% (1 threads)\nTree segmentation: 69% (1 threads)\nTree segmentation: 70% (1 threads)\nTree segmentation: 71% (1 threads)\nTree segmentation: 72% (1 threads)\nTree segmentation: 73% (1 threads)\nTree segmentation: 74% (1 threads)\nTree segmentation: 75% (1 threads)\nTree segmentation: 76% (1 threads)\nTree segmentation: 77% (1 threads)\nTree segmentation: 78% (1 threads)\nTree segmentation: 79% (1 threads)\nTree segmentation: 80% (1 threads)\nTree segmentation: 81% (1 threads)\nTree segmentation: 82% (1 threads)\nTree segmentation: 83% (1 threads)\nTree segmentation: 84% (1 threads)\nTree segmentation: 85% (1 threads)\nTree segmentation: 86% (1 threads)\nTree segmentation: 87% (1 threads)\nTree segmentation: 88% (1 threads)\nTree segmentation: 89% (1 threads)\nTree segmentation: 90% (1 threads)\nTree segmentation: 91% (1 threads)\nTree segmentation: 92% (1 threads)\nTree segmentation: 93% (1 threads)\nTree segmentation: 94% (1 threads)\nTree segmentation: 95% (1 threads)\nTree segmentation: 96% (1 threads)\nTree segmentation: 97% (1 threads)\nTree segmentation: 100% (1 threads)\n\n\nplot(las, color = \"treeID\")\n# This algorithm does not seem pertinent for this dataset.\nThe li2012 algorithm segments the trees in the LiDAR point cloud based on local neighborhood information. However, it may not be optimal for this specific dataset."
  },
  {
    "objectID": "supplemental/S2_its.html#using-crown_metrics",
    "href": "supplemental/S2_its.html#using-crown_metrics",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Using crown_metrics()",
    "text": "Using crown_metrics()\nThe crown_metrics() function extracts metrics from the segmented trees using a user-defined function. We use the length of the Z coordinate to obtain the tree height as an example.\n\n# Generate metrics for each delineated crown\nmetrics &lt;- crown_metrics(las = las, func = ~list(n = length(Z)))\nmetrics\n\nSimple feature collection with 2018 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 2670505 ymin: 1258734 xmax: 2670755 ymax: 1258984\nz_range:       zmin: 2.02 zmax: 48.31\nProjected CRS: CH1903+ / LV95\nFirst 10 features:\n   treeID    n                       geometry\n1       1 1140 POINT Z (2670616 1258984 48...\n2       2 3404 POINT Z (2670625 1258975 47...\n3       3 1748 POINT Z (2670634 1258983 46...\n4       4 1579 POINT Z (2670642 1258975 46...\n5       5 2533 POINT Z (2670626 1258904 46...\n6       6 1573 POINT Z (2670647 1258978 45...\n7       7 1922 POINT Z (2670591 1258771 45.3)\n8       8 5630 POINT Z (2670642 1258953 45...\n9       9 1578 POINT Z (2670556 1258741 44...\n10     10 1283 POINT Z (2670652 1258949 44...\n\nplot(metrics[\"n\"], cex = 0.8)\n\n\n\n\n\n\n\n\nWe calculate the number of points (n) in each tree crown using a user-defined function, and then visualize the results."
  },
  {
    "objectID": "supplemental/S2_its.html#applying-user-defined-functions",
    "href": "supplemental/S2_its.html#applying-user-defined-functions",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Applying user-defined functions",
    "text": "Applying user-defined functions\nWe can map any user-defined function at the tree level using the crown_metrics() function, just like pixel_metrics(). Here, we calculate the convex hull area of each tree using a custom function f() and then visualize the results.\n\n# User defined function for area calculation\nf &lt;- function(x, y) {\n  # Get xy for tree\n  coords &lt;- cbind(x, y)\n  \n  # Convex hull\n  ch &lt;- chull(coords)\n  \n  # Close coordinates\n  ch &lt;- c(ch, ch[1])\n  ch_coords &lt;- coords[ch, ]\n  \n  # Generate polygon\n  p &lt;- sf::st_polygon(list(ch_coords))\n  \n  #calculate area\n  area &lt;- sf::st_area(p)\n\n  return(list(A = area))\n}\n\n# Apply user-defined function\nmetrics &lt;- crown_metrics(las = las, func = ~f(X, Y))\nmetrics\n\nSimple feature collection with 2018 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 2670505 ymin: 1258734 xmax: 2670755 ymax: 1258984\nz_range:       zmin: 2.02 zmax: 48.31\nProjected CRS: CH1903+ / LV95\nFirst 10 features:\n   treeID         A                       geometry\n1       1 117.07885 POINT Z (2670616 1258984 48...\n2       2 225.63075 POINT Z (2670625 1258975 47...\n3       3 152.64110 POINT Z (2670634 1258983 46...\n4       4  92.06825 POINT Z (2670642 1258975 46...\n5       5 112.30745 POINT Z (2670626 1258904 46...\n6       6  78.93495 POINT Z (2670647 1258978 45...\n7       7 153.69045 POINT Z (2670591 1258771 45.3)\n8       8 305.83890 POINT Z (2670642 1258953 45...\n9       9 104.63505 POINT Z (2670556 1258741 44...\n10     10 166.12705 POINT Z (2670652 1258949 44...\n\nplot(metrics[\"A\"], cex = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3rd party metric packages\n\n\n\nRemember that you can use 3rd party packages like lidRmetrics for crown metrics too!"
  },
  {
    "objectID": "supplemental/S2_its.html#using-pre-defined-metrics",
    "href": "supplemental/S2_its.html#using-pre-defined-metrics",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Using pre-defined metrics",
    "text": "Using pre-defined metrics\nSome metrics are already recorded, and we can directly calculate them at the tree level using crown_metrics().\n\nmetrics &lt;- crown_metrics(las = las, func = .stdtreemetrics)\nmetrics\n\nSimple feature collection with 2018 features and 4 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 2670505 ymin: 1258734 xmax: 2670755 ymax: 1258984\nz_range:       zmin: 2.02 zmax: 48.31\nProjected CRS: CH1903+ / LV95\nFirst 10 features:\n   treeID     Z npoints convhull_area                       geometry\n1       1 48.31    1140       117.079 POINT Z (2670616 1258984 48...\n2       2 47.43    3404       225.631 POINT Z (2670625 1258975 47...\n3       3 46.56    1748       152.641 POINT Z (2670634 1258983 46...\n4       4 46.46    1579        92.068 POINT Z (2670642 1258975 46...\n5       5 46.01    2533       112.307 POINT Z (2670626 1258904 46...\n6       6 45.93    1573        78.935 POINT Z (2670647 1258978 45...\n7       7 45.30    1922       153.690 POINT Z (2670591 1258771 45.3)\n8       8 45.27    5630       305.839 POINT Z (2670642 1258953 45...\n9       9 44.81    1578       104.635 POINT Z (2670556 1258741 44...\n10     10 44.81    1283       166.127 POINT Z (2670652 1258949 44...\n\n# Visualize individual metrics\nplot(x = metrics[\"convhull_area\"], cex = 0.8)\n\n\n\n\n\n\n\nplot(x = metrics[\"Z\"], cex = 0.8)\n\n\n\n\n\n\n\n\nWe calculate tree-level metrics using .stdtreemetrics and visualize individual metrics like convex hull area and height."
  },
  {
    "objectID": "supplemental/S2_its.html#delineating-crowns",
    "href": "supplemental/S2_its.html#delineating-crowns",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Delineating crowns",
    "text": "Delineating crowns\nThe crown_metrics() function segments trees and extracts metrics at the crown level.\n\ncvx_hulls &lt;- crown_metrics(las = las, func = .stdtreemetrics, geom = 'convex')\ncvx_hulls\n\nSimple feature collection with 2018 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2670505 ymin: 1258734 xmax: 2670755 ymax: 1258984\nProjected CRS: CH1903+ / LV95\nFirst 10 features:\n   treeID     Z npoints convhull_area                       geometry\n1       1 48.31    1140       117.079 POLYGON ((2670624 1258979, ...\n2       2 47.43    3404       225.631 POLYGON ((2670635 1258974, ...\n3       3 46.56    1748       152.641 POLYGON ((2670643 1258978, ...\n4       4 46.46    1579        92.068 POLYGON ((2670646 1258971, ...\n5       5 46.01    2533       112.307 POLYGON ((2670636 1258903, ...\n6       6 45.93    1573        78.935 POLYGON ((2670652 1258975, ...\n7       7 45.30    1922       153.690 POLYGON ((2670596 1258764, ...\n8       8 45.27    5630       305.839 POLYGON ((2670652 1258954, ...\n9       9 44.81    1578       104.635 POLYGON ((2670558 1258738, ...\n10     10 44.81    1283       166.127 POLYGON ((2670655 1258944, ...\n\nplot(cvx_hulls)\nplot(ttops, add = TRUE, cex = 0.5)\n\nWarning in plot.sf(ttops, add = TRUE, cex = 0.5): ignoring all but the first\nattribute\n\n\n\n\n\n\n\n\n# Visualize individual metrics based on values\nplot(x = cvx_hulls[\"convhull_area\"])\n\n\n\n\n\n\n\nplot(x = cvx_hulls[\"Z\"])\n\n\n\n\n\n\n\n\nWe use crown_metrics() with .stdtreemetrics to segment trees and extract metrics based on crown delineation."
  },
  {
    "objectID": "supplemental/S2_its.html#itd-using-lascatalog",
    "href": "supplemental/S2_its.html#itd-using-lascatalog",
    "title": "Individual Tree Detection & Segmentation",
    "section": "ITD using LAScatalog",
    "text": "ITD using LAScatalog\nIn this section, we explore Individual Tree Detection (ITD) using the LAScatalog. We first configure catalog options for ITD.\n\n# Load catalog\nctg &lt;- catalog('data/ctg_norm')\n\n# Set catalog options\nopt_filter(ctg) &lt;- \"-drop_z_below 0 -drop_z_above 50\"\nopt_select(ctg) &lt;- \"xyz\"\nopt_chunk_size(ctg) &lt;- 500\nopt_chunk_buffer(ctg) &lt;- 10\nopt_progress(ctg) &lt;- TRUE\n\n# Explicitly tell R to use the is.empty function from the lidR package - avoid terra error\nis.empty &lt;- lidR::is.empty\n\n# Detect treetops and plot\nttops &lt;- locate_trees(las = ctg, algorithm = lmf(ws = 3, hmin = 10))\n\n\n\n\n\n\n\n\nChunk 1 of 9 (11.1%): state ✓\n\n                                                                                \nChunk 2 of 9 (22.2%): state ✓\n\n                                                                                \nChunk 3 of 9 (33.3%): state ✓\n\n                                                                                \nChunk 4 of 9 (44.4%): state ✓\n\n                                                                                \nChunk 5 of 9 (55.6%): state ✓\n\n                                                                                \nChunk 6 of 9 (66.7%): state ✓\n\n                                                                                \nChunk 7 of 9 (77.8%): state ✓\n\n                                                                                \nChunk 8 of 9 (88.9%): state ✓\n\n                                                                                \nChunk 9 of 9 (100%): state ✓\n\n                                                                                \n\nchm &lt;- rasterize_canopy(ctg, algorithm = p2r(), res = 1)\n\n\n\n\n\n\n\n\nChunk 1 of 9 (11.1%): state ✓\n\n                                                                                \nChunk 2 of 9 (22.2%): state ✓\n\n                                                                                \nChunk 3 of 9 (33.3%): state ✓\n\n                                                                                \nChunk 4 of 9 (44.4%): state ✓\n\n                                                                                \nChunk 5 of 9 (55.6%): state ✓\n\n                                                                                \nChunk 6 of 9 (66.7%): state ✓\n\n                                                                                \nChunk 7 of 9 (77.8%): state ✓\n\n                                                                                \nChunk 8 of 9 (88.9%): state ✓\n\n                                                                                \nChunk 9 of 9 (100%): state ✓\n\n                                                                                \n\nplot(chm)\nplot(ttops, add = TRUE, cex = 0.1, col = \"red\")"
  },
  {
    "objectID": "supplemental/S2_its.html#conclusion",
    "href": "supplemental/S2_its.html#conclusion",
    "title": "Individual Tree Detection & Segmentation",
    "section": "Conclusion",
    "text": "Conclusion\nThis concludes the tutorial on various methods for tree detection, segmentation, and extraction of metrics using the lidR package in R."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "lidR: (A workshop for) Airborne Lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "",
    "text": "Presenters:\nLiam Irwin (UBC)\nBrent Murray (UBC)"
  },
  {
    "objectID": "index.html#people",
    "href": "index.html#people",
    "title": "lidR: (A workshop for) Airborne Lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "",
    "text": "Presenters:\nLiam Irwin (UBC)\nBrent Murray (UBC)"
  },
  {
    "objectID": "index.html#materials",
    "href": "index.html#materials",
    "title": "lidR: (A workshop for) Airborne Lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "Materials",
    "text": "Materials\nThis repository contains the material for an 80 minute lidR tutorial workshop. You should install the material on your own machine from this repository. It contains the code and point-clouds we will use. The workshop intends to:\n\nPresent an overview of what can be done with lidR\nGive users an understanding of how lidR may fit their needs\nExercises will be done depending on available time - users are encouraged to work on these after the workshop!\n\n\n\n\n\n\n\nTip\n\n\n\nIntroduction slides: Intro to Airborne LiDAR & lidR"
  },
  {
    "objectID": "index.html#download-workshop-materials",
    "href": "index.html#download-workshop-materials",
    "title": "lidR: (A workshop for) Airborne Lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "Download Workshop Materials",
    "text": "Download Workshop Materials\nYou can download the complete workshop package containing all code, data, and exercises here:\nDownload the LPS lidR Tutorial Package (.zip, 26 MB)\nDownload additional classified lidar files for 05_engine (.zip, 80 MB)\nDownload additional normalized lidar files for 05_engine (.zip, 78 MB)\nUnzip the first to a folder, and run the .Rproj file with RStudio installed for the easiest experience. Unzip ctg_class.zip and ctg_norm.zip to their respective folders in data/ctg_*\n\n\n\nTarget Folder and Data Structure for Workshop Contents"
  },
  {
    "objectID": "index.html#requirements",
    "href": "index.html#requirements",
    "title": "lidR: (A workshop for) Airborne Lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "Requirements",
    "text": "Requirements\n\nR version and Rstudio\n\nYou need to install a recent version of R i.e. R 4.x or newer.\nWe will work with Rstudio. This IDE is not mandatory to follow the workshop but is highly recommended.\n\n\n\nR Packages\n\n\n\n\n\n\nTip\n\n\n\nEasy setup for new users Please open the LPS_lidRtutorial_package.Rproj in RStudio. Next, open 01_read.R to run code to automatically install packages.\n\n\nPlease install the lidR package in its latest version (4.2.1).\ninstall.packages(\"lidR\")\nTo run all code in the tutorial locally, you will need to install the following packages. You can use lidR without them or follow along with provided code and outputs.\nlibs &lt;- c(\"terra\",\"viridis\",\"future\",\"sf\",\"mapview\")\n\ninstall.packages(libs)\nIn the metrics section we introduce and work with a user-made package that supports lidR with additional functions to generate layers useful in vegetation and biodiversity mapping.\nTo follow along with these steps; install lidRmetrics from GitHub (not available on CRAN), this requires the devtools package\nif (!requireNamespace(\"devtools\", quietly = TRUE)) {\n  install.packages(\"devtools\")\n}\n\ndevtools::install_github(\"ptompalski/lidRmetrics\")\n\n\nDatasets\nWe will be working with a sample ALS dataset openly available for Canton Zürich flown in spring 2014.\nThe raw data has been thinned to a uniform density (20 points/m2) to speed up processing."
  },
  {
    "objectID": "index.html#estimated-schedule",
    "href": "index.html#estimated-schedule",
    "title": "lidR: (A workshop for) Airborne Lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "Estimated schedule",
    "text": "Estimated schedule\n\nIntroduction to Lidar and lidR (09:00)\nReading LAS and LAZ files (09:10)\nPoint Classification and filtering (9:15)\nDigital Terrain Models and Height Normalization (9:25)\nCanopy Height Models (9:35)\nLidar Summary Metrics (9:50)\nFile Collection Processing Engine (10:10)"
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "lidR: (A workshop for) Airborne Lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "Resources",
    "text": "Resources\nWe strongly recommend having the following resources available to you:\n\nThe lidR official documentation\nThe lidRbook of tutorials\n\nWhen working on exercises:\n\nStack Exchange with the lidR tag"
  },
  {
    "objectID": "index.html#lidr",
    "href": "index.html#lidr",
    "title": "lidR: (A workshop for) Airborne Lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "lidR",
    "text": "lidR\nlidR is an R package to work with LiDAR data developed at Laval University (Québec, Canada). It was developed & continues to be maintained by Jean-Romain Roussel and was made possible between:\n\n2015 and 2018 thanks to the financial support of the AWARE project NSERC CRDPJ 462973-14; grantee Prof. Nicholas C. Coops.\n2018 and 2021 thanks to the financial support of the Ministère des Forêts, de la Faune et des Parcs (Québec).\n2021 and 2024 thanks to the financial support of Laval University.\n\nThe current release version of lidR can be found on CRAN and source code is hosted on GitHub.\n\n\n\n\n\n\nNote\n\n\n\n\n\nNote\nSince 2024, the lidR package is no longer supported by Laval University, but the software will remain free and open-source. r-lidar has transitioned into a company to ensure sustainability and now offers independent services for training courses, consulting, and development. Please feel free to visit their website for more information."
  },
  {
    "objectID": "index.html#note",
    "href": "index.html#note",
    "title": "lidR: (A workshop for) Airborne Lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "Note",
    "text": "Note\nSince 2024, the lidR package is no longer supported by Laval University, but the software will remain free and open-source. r-lidar has transitioned into a company to ensure sustainability and now offers independent services for training courses, consulting, and development. Please feel free to visit their website for more information."
  },
  {
    "objectID": "06_solutions.html",
    "href": "06_solutions.html",
    "title": "Excercise Solutions",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "06_solutions.html#resources",
    "href": "06_solutions.html#resources",
    "title": "Excercise Solutions",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "06_solutions.html#las",
    "href": "06_solutions.html#las",
    "title": "Excercise Solutions",
    "section": "1-LAS",
    "text": "1-LAS\n\n# Load packages\nlibrary(sf)\nlibrary(terra)\nlibrary(lidR)\nlibrary(lidRmetrics)\n\n\nE1.\nUsing the plot() function plot the point cloud with a different attribute that has not been done yet\nTry adding axis = TRUE, legend = TRUE to your plot argument plot(las, axis = TRUE, legend = TRUE)\n\n\nCode\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\")\n\n\nCode\nplot(las, color = \"ReturnNumber\", axis = TRUE, legend = TRUE)\n\n\n\n\nE2.\nCreate a filtered las object of returns that have an Intensity greater that 50, and plot it.\n\n\nCode\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\")\n\n\nCode\ni_50 &lt;- filter_poi(las = las, Intensity &gt; 50)\nplot(i_50)\n\n\n\n\nE3.\nRead in the las file with only xyz and intensity only. Hint go to the lidRbook section to find out how to do this.\n\n\nCode\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\", select = \"xyzi\")"
  },
  {
    "objectID": "06_solutions.html#dtm",
    "href": "06_solutions.html#dtm",
    "title": "Excercise Solutions",
    "section": "2-DTM",
    "text": "2-DTM\n\nE1.\nCompute two DTMs for this point cloud with differing spatial resolutions, plot both e.g. `plot(dtm1)\n\n\nCode\nlas &lt;- readLAS(files = \"data/zrh_class.laz\")\n\n\nCode\ndtm_5 &lt;- rasterize_terrain(las=las, res=5, algorithm=tin())\ndtm_10 &lt;- rasterize_terrain(las=las, res=10, algorithm=tin())\nplot(dtm_5)\n\n\n\n\n\n\n\n\n\nCode\nplot(dtm_10)\n\n\n\n\n\n\n\n\n\n\n\nE2.\nNow use the plot_dtm3d() function to visualize and move around your newly created DTMs\n\n\nCode\nplot_dtm3d(dtm_5)"
  },
  {
    "objectID": "06_solutions.html#chm",
    "href": "06_solutions.html#chm",
    "title": "Excercise Solutions",
    "section": "3-CHM",
    "text": "3-CHM\n\nE1.\nUsing the p2r() and pitfree() (defining your own arguments) create two CHMs with the same resolution and plot them. What differences do you notice?\n\n\nCode\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\")\n\n\nCode\nchm_p2r &lt;- rasterize_canopy(las=las, res=2, algorithm=p2r())\n\nthresholds &lt;- c(0, 5, 10, 20, 25, 30)\nmax_edge &lt;- c(0, 1.35)\nchm_pitfree &lt;- rasterize_canopy(las = las, res = 2, algorithm = pitfree(thresholds, max_edge))\n\nplot(chm_p2r)\n\n\n\n\n\n\n\n\n\nCode\nplot(chm_pitfree)\n\n\n\n\n\n\n\n\n\n\n\nE2.\nUsing terra::focal() with the w = matrix(1, 5, 5) and fun = max, plot a manipulated CHM using one of the CHMs you previously generated.\n\n\nCode\nschm &lt;- terra::focal(chm_pitfree, w = matrix(1, 5, ,5), fun = max, na.rm = TRUE)\nplot(schm)\n\n\n\n\n\n\n\n\n\n\n\nE3.\nCreate a 10 m CHM using a algorithm of your choice. Would this information still be useful at this scale?\n\n\nCode\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\")\n\n\nCode\nchm &lt;- rasterize_canopy(las=las, res=10, algorithm=p2r())\nplot(chm)"
  },
  {
    "objectID": "06_solutions.html#metrics",
    "href": "06_solutions.html#metrics",
    "title": "Excercise Solutions",
    "section": "4-METRICS",
    "text": "4-METRICS\n\nE1.\nGenerate another metric set provided by the lidRmetrics package (voxel metrics will take too long)\n\n\nCode\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\")\n\n\nCode\ndispersion &lt;- pixel_metrics(las, ~metrics_percentiles(z = Z), res = 20)\n\n\n\n\nE2.\nMap the density of ground returns at a 5 m resolution. Hint filter = -keep_class 2\n\n\nCode\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\", filter = \"-keep_class 2\")\n\n\nCode\ngnd &lt;- pixel_metrics(las, ~length(Z)/25, res=5)\nplot(gnd)\n\n\n\n\n\n\n\n\n\n\n\nE3.\nssuming that biomass is estimated using the equation B = 0.5 * mean Z + 0.9 * 90th percentile of Z applied on first returns only, map the biomass.\n\n\nCode\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\")\n\n\nCode\nB &lt;- pixel_metrics(las, ~0.5*mean(Z) + 0.9*quantile(Z, probs = 0.9), 10, filter = ~ReturnNumber == 1L)\nplot(B)"
  },
  {
    "objectID": "06_solutions.html#lascatalog",
    "href": "06_solutions.html#lascatalog",
    "title": "Excercise Solutions",
    "section": "6-LASCATALOG",
    "text": "6-LASCATALOG\n\nE1.\nCalculate a set of metrics from the lidRmetrics package on the catalogue (voxel metrics will take too long)\n\n\nCode\nctg &lt;- readLAScatalog(folder = \"data/ctg_norm\")\ndispersion &lt;- pixel_metrics(ctg, ~metrics_dispersion(z = Z, dz = 2, zmax = 30), res = 20)\n\n\n\n\n\n\n\n\n#&gt; Chunk 1 of 9 (11.1%): state ✓\n#&gt; \n                                                                                \nChunk 2 of 9 (22.2%): state ✓\n#&gt; \n                                                                                \nChunk 3 of 9 (33.3%): state ✓\n#&gt; \n                                                                                \nChunk 4 of 9 (44.4%): state ✓\n#&gt; \n                                                                                \nChunk 5 of 9 (55.6%): state ✓\n#&gt; \n                                                                                \nChunk 6 of 9 (66.7%): state ✓\n#&gt; \n                                                                                \nChunk 7 of 9 (77.8%): state ✓\n#&gt; \n                                                                                \nChunk 8 of 9 (88.9%): state ✓\n#&gt; \n                                                                                \nChunk 9 of 9 (100%): state ✓\n#&gt; \n                                                                                \nplot(dispersion)\n\n\n\n\n\n\n\n\n\n\nE2.\nRead in the non-normalized las catalog filtering the point cloud to only include first returns.\n\n\nCode\nctg &lt;- readLAScatalog(folder = \"data/ctg_class\")\nopt_filter(ctg) &lt;- \"-keep_first -keep_class 2\"\n\n\n\n\nE3.\nGenerate a DTM at 1m spatial resolution for the provided catalog with only first returns.\n\n\nCode\ndtm_first &lt;- rasterize_terrain(ctg, res = 1, algorithm = tin())\n\n\n\n\n\n\n\n\n#&gt; Chunk 1 of 9 (11.1%): state ✓\n#&gt; \n                                                                                \nChunk 2 of 9 (22.2%): state ✓\n#&gt; \n                                                                                \nChunk 3 of 9 (33.3%): state ✓\n#&gt; \n                                                                                \nChunk 4 of 9 (44.4%): state ✓\n#&gt; \n                                                                                \nChunk 5 of 9 (55.6%): state ✓\n#&gt; \n                                                                                \nChunk 6 of 9 (66.7%): state ✓\n#&gt; \n                                                                                \nChunk 7 of 9 (77.8%): state ✓\n#&gt; \n                                                                                \nChunk 8 of 9 (88.9%): state ✓\n#&gt; \n                                                                                \nChunk 9 of 9 (100%): state ✓\n#&gt; \n                                                                                \nplot(dtm_first)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe Multiple Returns and Canopy Penetration This exercise highlights a critical and unique capability of Airborne Laser Scanning (ALS).\nUnlike methods based on imagery like Digital Aerial Photogrammetry (DAP), map the visible surface, LiDAR pulses can penetrate through gaps in the vegetation generating multiple returns each. This allows us to map the ground surface even under dense forest cover, which is essential for creating accurate Digital Terrain Models (DTMs)."
  },
  {
    "objectID": "04_metrics.html",
    "href": "04_metrics.html",
    "title": "Lidar Summary Metrics",
    "section": "",
    "text": "Code\nlidRbook metrics section\nlidRbook modelling section\nlidRmetrics package for additional metrics"
  },
  {
    "objectID": "04_metrics.html#relevant-resources",
    "href": "04_metrics.html#relevant-resources",
    "title": "Lidar Summary Metrics",
    "section": "",
    "text": "Code\nlidRbook metrics section\nlidRbook modelling section\nlidRmetrics package for additional metrics"
  },
  {
    "objectID": "04_metrics.html#overview",
    "href": "04_metrics.html#overview",
    "title": "Lidar Summary Metrics",
    "section": "Overview",
    "text": "Overview\nThis code demonstrates an example of generating pixel-based summary metrics of lidar data. This is a common task to capture critical information describing the vertical distribution of lidar returns across a regular grid (raster). Pixel metrics are used in various predictive modelling tasks and often to capture critical vegetation characteristics ranging from height to variability and cover.\nBeyond statistical summary metrics such as (mean, max, sd, etc), many researchers have developed custom metrics linked to critical vegetation attributes such as leaf-area index, vertical complexity indices, etc.\nAdditional metrics can also be generated with lidR using voxel approaches, where three-dimensional sub-compartments are fit to better capture complexity — at the cost of vastly increasing computational requirements and introducing additional parameters.\nClassically, lidar metrics used in vegetation characterization typically fall under three categories:\n\nHeight metrics\nThese typically describe how tall the vegetation generally is. Often max height, mean height, and percentiles of height are important in the prediction of attributes including land cover, and continuous variables like biomass.\nVariability metrics\nMetrics describing the shape of the distribution of returns often capture additional signals useful for explaining the level of vegetation complexity within a pixel. Skewed versus bimodal distributions, for example, can represent a very dense upper canopy in a forest compared to a multi-layer stand.\nCover metrics\nOften referred directly to as canopy cover, these metrics generally describe the proportion of returns (as a %) above a certain threshold. Typically used to generally describe how much vegetation (e.g. above 2m) there is compared to ground and other lower surfaces (designed for forest).\n\n\n\n\n\n\n\n\n\n\nTwo-dimensional cross section of 20x20m area from zrh_norm.laz some metrics are generated and presented alongside the coordinates of the points within this example cell"
  },
  {
    "objectID": "04_metrics.html#environment",
    "href": "04_metrics.html#environment",
    "title": "Lidar Summary Metrics",
    "section": "Environment",
    "text": "Environment\n\n# Clear environment\nrm(list = ls(globalenv()))\n\n# Load packages\nlibrary(lidR)\nlibrary(terra)\nlibrary(lidRmetrics)"
  },
  {
    "objectID": "04_metrics.html#basic-usage",
    "href": "04_metrics.html#basic-usage",
    "title": "Lidar Summary Metrics",
    "section": "Basic Usage",
    "text": "Basic Usage\nTo begin we compute simple metrics including mean and max height of points within 10x10 m pixels and visualizing the results. The code shows how to compute multiple metrics simultaneously and use predefined metric sets. Advanced usage introduces user-defined metrics for more specialized calculations.\n\n# Load the normalized lidar data\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\")\n\nThe pixel_metrics() function calculates structural metrics within a defined spatial resolution (res).\n\n# Compute the mean height of points within 10x10 m pixels\nhmean &lt;- pixel_metrics(las = las, func = ~mean(Z), res = 10)\nhmean\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 26, 26, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 10, 10  (x, y)\n#&gt; extent      : 2670500, 2670760, 1258730, 1258990  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : CH1903+ / LV95 (EPSG:2056) \n#&gt; source(s)   : memory\n#&gt; name        :          V1 \n#&gt; min value   :  0.01491925 \n#&gt; max value   : 28.90163739\nplot(hmean)\n\n\n\n\n\n\n\nFigure 1: Raster of mean lidar return height (Z) calculated at a 10m resolution.\n\n\n\n\n\n\n# Compute the max height of points within 10x10 m pixels\nhmax &lt;- pixel_metrics(las = las, func = ~max(Z), res = 10)\nhmax\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 26, 26, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 10, 10  (x, y)\n#&gt; extent      : 2670500, 2670760, 1258730, 1258990  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : CH1903+ / LV95 (EPSG:2056) \n#&gt; source(s)   : memory\n#&gt; name        :    V1 \n#&gt; min value   :  0.93 \n#&gt; max value   : 48.31\nplot(hmax)\n\n\n\n\n\n\n\nFigure 2: Raster of maximum lidar return height (Z) calculated at a 10m resolution.\n\n\n\n\n\nYou can specify that multiple metrics should be calculated by housing them in a list().\n\n# Compute several metrics at once using a list\nmetrics &lt;- pixel_metrics(las = las, func = ~list(hmax = max(Z), hmean = mean(Z)), res = 10)\nmetrics\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 26, 26, 2  (nrow, ncol, nlyr)\n#&gt; resolution  : 10, 10  (x, y)\n#&gt; extent      : 2670500, 2670760, 1258730, 1258990  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : CH1903+ / LV95 (EPSG:2056) \n#&gt; source(s)   : memory\n#&gt; names       :  hmax,       hmean \n#&gt; min values  :  0.93,  0.01491925 \n#&gt; max values  : 48.31, 28.90163739\nplot(metrics)\n\n\n\n\n\n\n\nFigure 3: Raster plot showing multiple metrics (maximum and mean height) calculated simultaneously at 10m resolution.\n\n\n\n\n\nPre-defined metric sets are available, such as .stdmetrics_z. See more here.\n\n# Simplify computing metrics with predefined sets of metrics\nmetrics &lt;- pixel_metrics(las = las, func = .stdmetrics_z, res = 10)\nmetrics\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 26, 26, 36  (nrow, ncol, nlyr)\n#&gt; resolution  : 10, 10  (x, y)\n#&gt; extent      : 2670500, 2670760, 1258730, 1258990  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : CH1903+ / LV95 (EPSG:2056) \n#&gt; source(s)   : memory\n#&gt; names       :  zmax,       zmean,         zsd,     zskew,      zkurt,   zentropy, ... \n#&gt; min values  :  0.93,  0.01491925,  0.07074514, -2.027288,   1.109003, 0.02902023, ... \n#&gt; max values  : 48.31, 28.90163739, 17.97744082, 16.645088, 308.212065, 0.93158775, ...\nplot(metrics)\n\n\n\n\n\n\n\nFigure 4: Range of Metrics Raster calculated from predefined .stdmetrics_z set.\n\n\n\n\n\nWe can examine the distribution of the standard deviation of return heights across the 10m grid cells by sub-setting this metric and plotting the raster. Even this simple metric demonstrates the variability in vertical vegetation structure across this dataset.\n\n# Plot a specific metric from the predefined set\nplot(metrics, \"zsd\")\n\n\n\n\n\n\n\nFigure 5: Raster of the standard deviation of lidar return heights (zsd), a metric from the .stdmetrics_z set."
  },
  {
    "objectID": "04_metrics.html#advanced-usage-with-user-defined-metrics",
    "href": "04_metrics.html#advanced-usage-with-user-defined-metrics",
    "title": "Lidar Summary Metrics",
    "section": "Advanced Usage with User-Defined Metrics",
    "text": "Advanced Usage with User-Defined Metrics\n\n\n\n\n\n\n3rd party lidar metrics packages\n\n\n\nlidR provides flexibility for users to define custom metrics. Check out 3rd party packages like lidRmetrics for suites of advanced metrics typically demonstrated in peer-reviewed articles and implemented in lidR through lidRmetrics.\n\n\nWe will present several metrics often tied to vegetation and biodiversity, for an overview of connecting metrics with habitat see this article.\nCanopy Cover\nCanopy cover is often estimated using the proportion of lidar returns generated over some threshold. Two metres is commonly used, ultimately canopy cover seeks to quantify relatively how much vegetation (points) is present.\n\ncc_metrics &lt;- pixel_metrics(las, func = ~metrics_percabove(z = Z, threshold = 2, zmin = 0), res = 10)\nplot(cc_metrics)\n\n\n\n\n\n\n\nFigure 6: Canopy cover metric, calculated as the proportion of lidar returns above a 2m threshold.\n\n\n\n\n\nLeaf Area Density Profiles (Bouvier et al. 2015)\nLeaf Area Density (LAD) profiles describe the vertical distribution of foliage within the canopy. The method estimates the amount of leaf material in successive horizontal layers by modeling how lidar pulses are intercepted as they travel down through the vegetation.\n\nlad_metrics &lt;- pixel_metrics(las, ~metrics_lad(z = Z), res = 10)\nplot(lad_metrics)\n\n\n\n\n\n\n\nFigure 7: Raster plots of Leaf Area Density (LAD) profile metrics, calculated at 10m resolution.\n\n\n\n\n\nThe Coefficient of Variation of LAD (lad_cv) quantifies the uniformity of the vertical foliage distribution. A high lad_cv value indicates that foliage is concentrated in a specific layer (e.g., a simple, even-aged canopy), while a low value suggests foliage is more evenly spread across multiple layers, indicating greater vertical complexity.\n\nplot(lad_metrics, \"lad_cv\")\n\n\n\n\n\n\n\n\nRaster plot of the Coefficient of Variation of Leaf Area Density (lad_cv) calculated at 10m resolution.\n\n\n\n\nDispersion and Vertical Complexity\nWhile standard deviation (zsd) gives a general sense of height variability, dispersion metrics provide a more nuanced characterization of how lidar points are distributed vertically within the canopy. They help quantify the structural complexity of vegetation, which is crucial for applications like habitat modeling and biomass estimation.\n\n# Calculate several dispersion metrics. zmax is required to compute VCI.\ndisp_metrics &lt;- pixel_metrics(las, ~metrics_dispersion(z = Z, zmax = 40), res = 10)\nplot(disp_metrics)\n\n\n\n\n\n\n\nFigure 8: A collection of dispersion metrics calculated at 10m resolution.\n\n\n\n\n\nCanopy Relief Ratio (CRR) measures the position of the mean point height relative to the overall height range of the canopy. It is calculated as (mean(Z) - min(Z)) / (max(Z) - min(Z)). A value closer to 1 suggests that most of the vegetation volume is concentrated in the upper parts of the canopy.\n\nplot(disp_metrics, \"CRR\")\n\n\n\n\n\n\n\nFigure 9: Canopy Relief Ratio (CRR) at 10m resolution, indicating the vertical position of the mean energy return within the canopy.\n\n\n\n\n\nVertical Complexity Index (VCI) uses entropy to quantify how evenly the lidar returns are distributed throughout the vertical profile. Higher VCI values indicate a more complex, multi-layered canopy structure (e.g., a forest with understory, mid-story, and overstory). Lower values suggest a simpler structure where points are clumped at specific heights (e.g., a field of grass or a dense, flat-topped plantation).\n\nplot(disp_metrics, \"VCI\")\n\n\n\n\n\n\n\nFigure 10: Vertical Complexity Index (VCI) at 10m resolution. Higher values indicate a more complex vertical distribution of vegetation.\n\n\n\n\n\nUser Defined Metrics\nWe can also create our own user-defined metric functions. This demonstrates the flexibility of the lidR package!\nHere we generate an arbitrary function to compute a weighted mean between two attributes. We then calculate the mean height of 10 m pixels weighted by return Intensity (albeit a potentially meaningless metric)\n\n# Generate a user-defined function to compute weighted mean between two attributes\nf &lt;- function(x, weight) { sum(x*weight)/sum(weight) }\n\n# Compute weighted mean of height (Z) as a function of return intensity\nuser_metric &lt;- pixel_metrics(las = las, func = ~f(Z, Intensity), res = 10)\n\n# Visualize the output\nplot(user_metric)\n\n\n\n\n\n\n\nFigure 11: Raster plot of a user-defined metric: the mean height (Z) weighted by return Intensity."
  },
  {
    "objectID": "04_metrics.html#exercises-and-questions",
    "href": "04_metrics.html#exercises-and-questions",
    "title": "Lidar Summary Metrics",
    "section": "Exercises and Questions",
    "text": "Exercises and Questions\nUsing:\nlas &lt;- readLAS(\"data/zrh_norm.laz\")\n\nE1.\nGenerate another metric set provided by the lidRmetrics package (voxel metrics will take too long)\n\n\nE2.\nMap the density of ground returns at a 5 m resolution (in points/m2). Hints: filter = -keep_class 2 - what’s the area of a 5 m pixel?\n\n\nE3.\nAssuming that biomass is estimated using the equation B = 0.5 * mean Z + 0.9 * 90th percentile of Z applied on first returns only, map the biomass."
  },
  {
    "objectID": "04_metrics.html#conclusion",
    "href": "04_metrics.html#conclusion",
    "title": "Lidar Summary Metrics",
    "section": "Conclusion",
    "text": "Conclusion\nIn this tutorial, we covered basic usage of the lidR package for computing mean and max heights within grid cells and using predefined sets of metrics. Additionally, we explored the advanced usage with the ability to define user-specific metrics for grid computation."
  },
  {
    "objectID": "02_dtm.html",
    "href": "02_dtm.html",
    "title": "Digital Terrain Models",
    "section": "",
    "text": "Code\nlidRbook section"
  },
  {
    "objectID": "02_dtm.html#relevant-resources",
    "href": "02_dtm.html#relevant-resources",
    "title": "Digital Terrain Models",
    "section": "",
    "text": "Code\nlidRbook section"
  },
  {
    "objectID": "02_dtm.html#overview",
    "href": "02_dtm.html#overview",
    "title": "Digital Terrain Models",
    "section": "Overview",
    "text": "Overview\nAirborne Laser Scanning has for decades been used to generate detailed models of terrain based on lidar measurements. Lidar’s ability to produce consistent wall-to-wall ground measurements, even when obscured by vegetation is a critical advantage of the technology in environmental mapping.\nDigital Terrain Models (DTMs) are gridded (raster) surfaces generated at a given spatial resolution with an interpolation method that populates each cell with an elevation value.\nThis tutorial explores the creation of DTMs from lidar data. It demonstrates two algorithms for DTM generation: ground point triangulation, and inverse-distance weighting. Additionally, the tutorial showcases DTM-based normalization and point-based normalization, accompanied by exercises for hands-on practice."
  },
  {
    "objectID": "02_dtm.html#environment",
    "href": "02_dtm.html#environment",
    "title": "Digital Terrain Models",
    "section": "Environment",
    "text": "Environment\n\n# Clear environment\nrm(list = ls(globalenv()))\n\n# Load packages\nlibrary(lidR)"
  },
  {
    "objectID": "02_dtm.html#dtm-digital-terrain-model",
    "href": "02_dtm.html#dtm-digital-terrain-model",
    "title": "Digital Terrain Models",
    "section": "DTM (Digital Terrain Model)",
    "text": "DTM (Digital Terrain Model)\nIn this section, we’ll generate a Digital Terrain Model (DTM) from lidar data using two different algorithms: tin() and knnidw().\n\nData Preprocessing\n\n# Load lidar data where points are already pre-classified\nlas &lt;- readLAS(files = \"data/zrh_class.laz\")\n\n\n\nVisualizing Lidar Data\nWe start by visualizing the entire lidar point cloud to get an initial overview.\nplot(las)\nVisualizing the Lidar data again, this time to distinguish ground points (blue) more effectively.\nplot(las, color = \"Classification\")\n\n\nTriangulation Algorithm - tin()\nWe create a DTM using the tin() algorithm with a resolution of 1 meter.\n\n# Generate a DTM using the TIN (Triangulated Irregular Network) algorithm\ndtm_tin &lt;- rasterize_terrain(las = las, res = 1, algorithm = tin())\n\n\n\n\n\n\n\nDegenerated points\n\n\n\nYou may receive a warning about degenerated points when creating a DTM. A degenerated point in lidar data refers to a point with identical XY(Z) coordinates as another point. This means two or more points occupy exactly the same location in XY/3D space. Degenerated points can cause issues in tasks like creating a digital terrain model, as they don’t add new information and can lead to inconsistencies. Identifying and handling degenerated points appropriately is crucial for accurate and meaningful results.\n\n\n\n\nVisualizing DTM in 3D\nTo better conceptualize the terrain, we visualize the generated DTM in a 3D plot.\n# Visualize the DTM in 3D\nplot_dtm3d(dtm_tin)\n\n\nVisualizing DTM with Lidar Point Cloud\nWe overlay the DTM on the lidar data (non-ground points only) for a more comprehensive view of the terrain.\n# Filter for non-ground points to show dtm better\nlas_ng &lt;- filter_poi(las = las, Classification != 2L)\n\n# Visualize the lidar data with the overlaid DTM in 3D\nx &lt;- plot(las_ng, bg = \"white\")\nadd_dtm3d(x, dtm_tin, bg = \"white\")\n\n\nInverse-Distance Weighting (IDW) Algorithm - knnidw()\nNext, we generate a DTM using the IDW algorithm to compare results with the TIN-based DTM.\n\n# Generate a DTM using the IDW (Inverse-Distance Weighting) algorithm\ndtm_idw &lt;- rasterize_terrain(las = las, res = 1, algorithm = knnidw())\n\n\n\nVisualizing IDW-based DTM in 3D\nWe visualize the DTM generated using the IDW algorithm in a 3D plot.\n# Visualize the IDW-based DTM in 3D\nplot_dtm3d(dtm_idw)"
  },
  {
    "objectID": "02_dtm.html#height-normalization",
    "href": "02_dtm.html#height-normalization",
    "title": "Digital Terrain Models",
    "section": "Height Normalization",
    "text": "Height Normalization\nHeight normalization is applied by subtracting terrain height from return heights above the ground level. This serves to remove distortion from topography and isolate vegetation structure. In doing so elevation (Z coordinates) of each return is converted from height above some reference surface; such as sea level (mASL) to above ground (mAGL)\nNormalization is a critical pre-processing step that enables the signal of vegetation structure to be isolated and mapped.\nWe’ll perform height normalization of lidar data using both DTM-based and point-based normalization methods.\n\np_las\n\n\n\n\n\n\n\nFigure 1: Two-dimensional cross section (0.5m wide) showing raw non-normalized points\n\n\n\n\n\n\np_norm\n\n\n\n\n\n\n\nFigure 2: Two-dimensional cross section (0.5m wide) showing ground normalized points\n\n\n\n\n\n\nDTM-based Normalization\nFirst, we perform DTM-based normalization on the lidar data using the previously generated DTM.\n\n# Normalize the lidar data using DTM-based normalization\nnlas_dtm &lt;- normalize_height(las = las, algorithm = dtm_tin)\n\n\n\nVisualizing Normalized Lidar Data\nWe visualize the normalized lidar data, illustrating heights relative to the DTM (mAGL).\n# Visualize the normalized lidar data\nplot(nlas_dtm)\n\n\nDTM-based Normalization with TIN Algorithm\nWe perform DTM-based normalization on the lidar data using the TIN algorithm. Rather than specifying a resolution for an interpolated DTM a triangular irregular network (TIN) will be directly fit to ground returns (on-the-fly) and used to normalize points elevations.\n\n# Normalize the lidar data using DTM-based normalization with TIN algorithm\nnlas_tin &lt;- normalize_height(las = las, algorithm = tin())\n\n\n\nVisualizing Normalized Lidar Data with TIN\nWe visualize the normalized lidar data using the TIN algorithm, showing heights relative to the DTM.\n\n# Visualize the normalized lidar data using the TIN algorithm\nplot(nlas_tin, bg = \"white\")"
  },
  {
    "objectID": "02_dtm.html#exercises",
    "href": "02_dtm.html#exercises",
    "title": "Digital Terrain Models",
    "section": "Exercises",
    "text": "Exercises\n\nE1.\nCompute two DTMs for this point cloud with differing spatial resolutions, plot both\n\n\nE2.\nNow use the plot_dtm3d() function to visualize and move around your newly created DTMs"
  },
  {
    "objectID": "02_dtm.html#conclusion",
    "href": "02_dtm.html#conclusion",
    "title": "Digital Terrain Models",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial covered the creation of Digital Terrain Models (DTMs) from lidar data using different algorithms and explored height normalization techniques. The exercises provided hands-on opportunities to apply these concepts, enhancing understanding and practical skills."
  },
  {
    "objectID": "01_read.html",
    "href": "01_read.html",
    "title": "Read/Plot/Query",
    "section": "",
    "text": "Code\nlidRbook section"
  },
  {
    "objectID": "01_read.html#relevant-resources",
    "href": "01_read.html#relevant-resources",
    "title": "Read/Plot/Query",
    "section": "",
    "text": "Code\nlidRbook section"
  },
  {
    "objectID": "01_read.html#overview",
    "href": "01_read.html#overview",
    "title": "Read/Plot/Query",
    "section": "Overview",
    "text": "Overview\nWelcome to this lidar processing tutorial using R and the lidR package! In this tutorial, you will learn how to read, visualize, and query lidar data. We’ll explore basic information about a lidar file including the header and data frame as well as visualize point clouds using different colour schemes based on attributes with plot(). We’ll use the select argument in readLAS() to load specific attributes and the filter argument to only load points of interest or apply transformations on-the-fly.\nLet’s get started with processing lidar data efficiently using lidR and R! Happy learning!"
  },
  {
    "objectID": "01_read.html#environment",
    "href": "01_read.html#environment",
    "title": "Read/Plot/Query",
    "section": "Environment",
    "text": "Environment\nWe start each page by loading the necessary packages, clearing our current environment, and specifying that some warnings be turned off to make our outputs clearer. We will do this for each section in the tutorial.\n\n# Clear environment\nrm(list = ls(globalenv()))\n\n# Load package\nlibrary(lidR)"
  },
  {
    "objectID": "01_read.html#basic-usage",
    "href": "01_read.html#basic-usage",
    "title": "Read/Plot/Query",
    "section": "Basic Usage",
    "text": "Basic Usage\n\nLoad and Inspect lidar Data\nLoad the lidar point cloud data from a LAS file using the readLAS() function. The data is stored in the las object. We can inspect the header information and attributes of the las object by calling the object.\n\n# Load the sample point cloud\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\")\n# Inspect header information and print a summary\nlas\n\nclass        : LAS (v1.1 format 1)\nmemory       : 67.8 Mb \nextent       : 2670505, 2670755, 1258734, 1258984 (xmin, xmax, ymin, ymax)\ncoord. ref.  : CH1903+ / LV95 \narea         : 63504 m²\npoints       : 1.27 million points\ntype         : airborne\ndensity      : 20 points/m²\ndensity      : 7.43 pulses/m²\n\n# Check the file size of the loaded lidar data\nformat(object.size(las), \"Mb\")\n\n[1] \"96.9 Mb\"\n\n\n\n\nVisualizing lidar Data\nWe can visualize the lidar data using the plot() function. We have several options to control the colours in the plot, such as selecting specific attributes from the data to be mapped.\n\n\n\n\n\n\nplot() background colour\n\n\n\nSet the background of plots to white using plot(las, bg = \"white\"). To keep the website code clean I’ve omitted this from examples.\n\n\nplot(las)"
  },
  {
    "objectID": "01_read.html#point-classification",
    "href": "01_read.html#point-classification",
    "title": "Read/Plot/Query",
    "section": "Point Classification",
    "text": "Point Classification\nLidar systems and pre-processing attribute point clouds with additional attributes beyond just X, Y and Z coordinates.\nFor instance, points are typically assigned Classification values to differentiate surfaces. This is often already done by the data provider or through user applied algorithms to classify for example noise and ground points. The meaning of these ID values depends on the LAS file version and source.\n\n\n\n\n\n\nNote\n\n\n\nLAS Standard Point classification is now standardized by the American Society for Photogrammetry and Remote Sensing (ASPRS). For a complete list of classes, refer to the LAS 1.4 specification (R15).\n\n\nOur example ALS dataset, collected in 2014 over Zürich uses an older LAS 1.1 standard. Its classification codes are interpreted as follows:\n\n\n\n\n\n\n\n\n\nClass Code\nMeaning\nInterpretation\nNumber of points\n\n\n\n\n2\nGround\nThe bare earth surface.\n195582\n\n\n3/4/5\nLow/Medium/High Vegetation\nVegetation under 1 meter.\n650123\n\n\n7\nNoise\nErroneous points, likely below ground or outliers above ground.\n87\n\n\n12\nOverlap Points\nPoints assigned to overlapping flight lines.\n424135\n\n\n\nplot(las, color = \"Classification\")\nLidar point clouds record Return Intensity information; representing the strength of the returning signal. This attribute varies widely depending on sensor/acquisition characteristics can be useful in biodiversity mapping.\nplot(las, color = \"Intensity\")\nLaser scanning systems record the scan angle of each pulse and attribute this information to the point cloud as ScanAngleRank.\nplot(las, color = \"ScanAngleRank\")"
  },
  {
    "objectID": "01_read.html#filtering-dataset",
    "href": "01_read.html#filtering-dataset",
    "title": "Read/Plot/Query",
    "section": "Filtering Dataset",
    "text": "Filtering Dataset\nOften we do not need the entire set of points or attributes (columns) loaded in memory for our analysis. We can use Classification as well as other attributes to pre-filter point clouds before further processing.\nThere are two key was in lidR to achieve this.\n\nFiltering points on-the-fly (efficient)\nFirst, we load subsets of the lidar points based on certain criteria using the filter argument in directly in readLAS().\nThe filter argument in readLAS() can be useful for tasks such as filtering specific classifications, to isolate ground, remove noise, etc…\n\n# Load point cloud keeping only Classification 2 (ground returns)\nlas &lt;- readLAS(files = \"data/zrh_class.laz\", filter = \"-keep_class 2\")\n\nVisualize the first return filtered point cloud using the plot() function.\nplot(las)\nEach lidar pulse can record multiple discrete returns (points).\nHere we use a filter during readLAS to subset only first returns.\n\n# Load only the first return points\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\", filter = \"-keep_first\")\n# Inspect the loaded points\nlas\n\nclass        : LAS (v1.1 format 1)\nmemory       : 25.2 Mb \nextent       : 2670505, 2670755, 1258734, 1258984 (xmin, xmax, ymin, ymax)\ncoord. ref.  : CH1903+ / LV95 \narea         : 63476 m²\npoints       : 471.7 thousand points\ntype         : airborne\ndensity      : 7.43 points/m²\ndensity      : 7.43 pulses/m²\n\n# Check the memory size after loading only the filtered points\nformat(object.size(las), \"Mb\")\n\n[1] \"36 Mb\"\n\n\nVisualize the first return filtered point cloud using the plot() function.\nplot(las)\nThe readLAS() function also allows us to select specific attributes (columns) to be loaded into memory. This is useful to reduce memory requirements when working with large lidar datasets.\n\n# Load only the xyz coordinates (X, Y, Z) and ignore other attributes\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\", select = \"xyz\")\n# Inspect the loaded attributes\nlas@data\n\n               X       Y     Z\n           &lt;num&gt;   &lt;num&gt; &lt;num&gt;\n      1: 2670506 1258984 18.57\n      2: 2670506 1258984 23.27\n      3: 2670506 1258984 20.64\n      4: 2670507 1258984  0.00\n      5: 2670505 1258983  0.00\n     ---                      \n1270076: 2670754 1258736 17.38\n1270077: 2670754 1258736 17.72\n1270078: 2670754 1258735 13.45\n1270079: 2670754 1258735 16.41\n1270080: 2670754 1258734 15.43\n\n# Check the memory size (much smaller)\nformat(object.size(las), \"Mb\")\n\n[1] \"29.1 Mb\"\n\n\n\n\n\n\n\n\nSee all readLAS pre-built filters\n\n\n\nrun readLAS(filter = \"-help\") for a full list of these filters.\n\n\n\n\nFiltering Points using filter_poi()\nAlternatively LASobjects loaded into memory with readLAS() can be filtered immediately using the filter_poi() function. These filters can be custom made by combining boolean operators (==, !=, &gt;, &lt;, &, |, etc…) with point cloud attributes to formulate logical statements. Statements are applied to points to assign TRUE (kept) or FALSE (filtered out) values.\n\n# Load the lidar file with all the all attributes \nlas &lt;- readLAS(files = \"data/zrh_class.laz\")\n# Filter points with Classification == 2\nclass_2 &lt;- filter_poi(las = las, Classification == 2L)\n\n# Combine queries to filter points with Classification 2 and ReturnNumber == 1\nfirst_returns &lt;- filter_poi(las = las, Classification == 2L & ReturnNumber == 1L)\n\nplot(class_2)\nplot(first_returns)"
  },
  {
    "objectID": "01_read.html#exercises-and-questions",
    "href": "01_read.html#exercises-and-questions",
    "title": "Read/Plot/Query",
    "section": "Exercises and Questions",
    "text": "Exercises and Questions\nUsing:\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\")\n\nE1.\nUsing the plot() function plot the point cloud with a different attribute that has not been done yet\nTry adding axis = TRUE, legend = TRUE to your plot argument plot(las, axis = TRUE, legend = TRUE)\n\n\nE2.\nCreate a filtered las object of returns that have an Intensity greater that 50, and plot it.\n\n\nE3.\nRead in the las file with only xyz and intensity only. Hint go to the lidRbook section to find out how to do this"
  },
  {
    "objectID": "01_read.html#conclusion",
    "href": "01_read.html#conclusion",
    "title": "Read/Plot/Query",
    "section": "Conclusion",
    "text": "Conclusion\nThis concludes our tutorial on the basic usage of the lidR package in R for processing and analyzing lidar data. We covered loading lidar data, inspecting and visualizing the data, selecting specific attributes, and filtering points of interest."
  },
  {
    "objectID": "03_chm.html",
    "href": "03_chm.html",
    "title": "Canopy Height Models",
    "section": "",
    "text": "Code\nlidRbook section"
  },
  {
    "objectID": "03_chm.html#relevant-resources",
    "href": "03_chm.html#relevant-resources",
    "title": "Canopy Height Models",
    "section": "",
    "text": "Code\nlidRbook section"
  },
  {
    "objectID": "03_chm.html#overview",
    "href": "03_chm.html#overview",
    "title": "Canopy Height Models",
    "section": "Overview",
    "text": "Overview\nThis code demonstrates the creation of a Canopy Height Model (CHM). Similar to the DTM, a CHM is a rasterized summary of the upper-most surface of the height normalized lidar point cloud. Often this is simply generated as maximum height for each cell. CHMs often serve as fundamental layers for vegetation and biodiversity related applications.\nWe present different algorithms for generating CHMs and provide options for adjusting resolution and filling empty pixels."
  },
  {
    "objectID": "03_chm.html#environment",
    "href": "03_chm.html#environment",
    "title": "Canopy Height Models",
    "section": "Environment",
    "text": "Environment\n\n# Clear environment\nrm(list = ls(globalenv()))\n\n# Load packages\nlibrary(lidR)\nlibrary(terra)"
  },
  {
    "objectID": "03_chm.html#data-preprocessing",
    "href": "03_chm.html#data-preprocessing",
    "title": "Canopy Height Models",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nOnce again we load the lidar in to memory with readLAS. this time however, we sample points randomly to decimate the point cloud and simulate lower density lidar data using decimate_points().\nThe sampling/return density of your point cloud (particularly those originating from the canopy surface for a CHM) dictates the lowest acceptable spatial resolution.\n\n# Load lidar data and reduce point density\nlas &lt;- readLAS(files = \"data/zrh_norm.laz\")\n\n# Density of the data is reduced from 20 points/m² to 10 points/m² for example purposes\nlas &lt;- decimate_points(las, random(density = 10))\n\n# Visualize the lidar point cloud\nplot(las)\n\n\n\n\n\n\n\n\nFigure 1: Normalized lidar point cloud used for generating the Canopy Height Model (CHM)."
  },
  {
    "objectID": "03_chm.html#point-to-raster-based-algorithm",
    "href": "03_chm.html#point-to-raster-based-algorithm",
    "title": "Canopy Height Models",
    "section": "Point-to-Raster Based Algorithm",
    "text": "Point-to-Raster Based Algorithm\nFirst we apply a simple method for generating Canopy Height Models (CHMs).\nBelow, the rasterize_canopy() function with the p2r() algorithm assigns the elevation of the highest point within each 2m grid cell to a corresponding pixel. The resulting CHM is then visualized using the plot() function.\n\n# Generate the CHM using a simple point-to-raster based algorithm\nchm &lt;- rasterize_canopy(las = las, res = 2, algorithm = p2r())\n\n# Visualize the CHM\nplot(chm)\n\n\n\n\n\n\n\nFigure 2: Canopy Height Model (CHM) generated at 2m resolution using the point-to-raster (p2r) algorithm.\n\n\n\n\n\nNext, by increasing the resolution of the CHM to 1m (reducing the grid cell size), we get a more detailed representation of the canopy, but also have more empty pixels.\n\n# Make spatial resolution 1 m\nchm &lt;- rasterize_canopy(las = las, res = 1, algorithm = p2r())\nplot(chm)\n\n\n\n\n\n\n\nFigure 3: CHM generated at a higher resolution of 1m using the p2r algorithm, showing more detail and some empty pixels.\n\n\n\n\n\nFurther increasing to 0.5m causes more empty pixels where no valid points are present. (see tiny white dots on CHM)\n\n# Using the 'subcircle' option turns each point into a disc of 8 points with a radius r\nchm &lt;- rasterize_canopy(las = las, res = 0.5, algorithm = p2r(subcircle = 0.15))\nplot(chm)\n\n\n\n\n\n\n\nFigure 4: A 0.5m resolution CHM created using the p2r algorithm with the subcircle option to fill gaps.\n\n\n\n\n\nThe rasterize_canopy() function with the p2r() algorithm allows the use of the subcircle option, which turns each lidar point into a disc of 8 points with a specified radius. This can help to capture more fine-grained canopy details, especially from lower density point clouds, resulting in a complete CHM.\nIncreasing the subcircle radius may not necessarily result in meaningful CHMs, as it could lead to over-smoothing or loss of important canopy information.\n\n# Increasing the subcircle radius, but it may not have meaningful results\nchm &lt;- rasterize_canopy(las = las, res = 0.5, algorithm = p2r(subcircle = 0.8))\nplot(chm)\n\n\n\n\n\n\n\nFigure 5: CHM generated with an increased subcircle radius, with potential over-smoothing.\n\n\n\n\n\nThe p2r() algorithm also allows filling empty pixels using TIN (Triangulated Irregular Network) interpolation, which can help in areas with sparse lidar points to obtain a smoother CHM.\n\n# We can fill empty pixels using TIN interpolation\nchm &lt;- rasterize_canopy(las = las, res = 0.5, algorithm = p2r(subcircle = 0.0, na.fill = tin()))\nplot(chm)\n\n\n\n\n\n\n\nFigure 6: CHM with empty pixels filled using Triangulated Irregular Network (TIN) interpolation."
  },
  {
    "objectID": "03_chm.html#triangulation-based-pitfree-algorithm",
    "href": "03_chm.html#triangulation-based-pitfree-algorithm",
    "title": "Canopy Height Models",
    "section": "Triangulation Based Pitfree Algorithm",
    "text": "Triangulation Based Pitfree Algorithm\nThe rasterize_canopy function can also use the Khosravipour et al. 2014 pitfree() algorithm with specified height thresholds and a maximum edge length to generate a CHM. This algorithm aims to correct depressions in the CHM surface, especially designed to prevent gaps in CHMs from low density lidar.\n\n\n\n\n\n\nPit-free algorithm\n\n\n\nCheck out Khosravipour et al. 2014 to see the original implementation of the algorithm!\n\n\n\n# Using the Khosravipour et al. 2014 pit-free algorithm with specified thresholds and maximum edge length\nthresholds &lt;- c(0, 5, 10, 20, 25, 30)\nmax_edge &lt;- c(0, 1.35)\nchm &lt;- rasterize_canopy(las = las, res = 0.5, algorithm = pitfree(thresholds, max_edge))\nplot(chm)\n\n\n\n\n\n\n\nFigure 7: CHM generated using the pitfree algorithm by Khosravipour et al. (2014).\n\n\n\n\n\nThe subcircle option can also be used with the pitfree() algorithm to create finer spatial resolution CHMs with subcircles for each lidar point, similar to the point-to-raster based algorithm.\n\n# Using the 'subcircle' option with the pit-free algorithm\nchm &lt;- rasterize_canopy(las = las, res = 0.25, algorithm = pitfree(thresholds, max_edge, 0.1))\nplot(chm)\n\n\n\n\n\n\n\nFigure 8: CHM generated using the pitfree algorithm combined with the subcircle option for finer detail."
  },
  {
    "objectID": "03_chm.html#post-processing",
    "href": "03_chm.html#post-processing",
    "title": "Canopy Height Models",
    "section": "Post-Processing",
    "text": "Post-Processing\nCHMs can be post-processed by smoothing or other manipulations. Here, we demonstrate post-processing using the terra::focal() function for average smoothing within a 3x3 moving window.\n\n# Post-process the CHM using the 'terra' package and focal() function for smoothing\nker &lt;- matrix(1, 3, 3)\nschm &lt;- terra::focal(chm, w = ker, fun = mean, na.rm = TRUE)\n\n# Visualize the smoothed CHM\nplot(schm)\n\n\n\n\n\n\n\nFigure 9: The pitfree CHM after post-processing with a 3x3 mean focal filter for smoothing."
  },
  {
    "objectID": "03_chm.html#exercises",
    "href": "03_chm.html#exercises",
    "title": "Canopy Height Models",
    "section": "Exercises",
    "text": "Exercises\n\nE1.\nUsing the p2r() and pitfree() (defining your own arguments) create two CHMs with the same resolution and plot them. What differences do you notice?\n\n\nE2.\nUsing terra::focal() with the w = matrix(1, 5, 5) and fun = max, plot a manipulated CHM using one of the CHMs you previously generated.\n\n\nE3.\nCreate a 10 m CHM using a algorithm of your choice. Would this information still be useful at this scale?"
  },
  {
    "objectID": "03_chm.html#conclusion",
    "href": "03_chm.html#conclusion",
    "title": "Canopy Height Models",
    "section": "Conclusion",
    "text": "Conclusion\nThis tutorial covered different algorithms for generating Canopy Height Models (CHMs) from lidar data using the lidR package in R. It includes point-to-raster-based algorithms and triangulation-based algorithms, as well as post-processing using the terra package."
  },
  {
    "objectID": "05_engine.html",
    "href": "05_engine.html",
    "title": "LAScatalog",
    "section": "",
    "text": "Code\nlidRbook section"
  },
  {
    "objectID": "05_engine.html#relevant-resources",
    "href": "05_engine.html#relevant-resources",
    "title": "LAScatalog",
    "section": "",
    "text": "Code\nlidRbook section"
  },
  {
    "objectID": "05_engine.html#overview",
    "href": "05_engine.html#overview",
    "title": "LAScatalog",
    "section": "Overview",
    "text": "Overview\nThis code performs various operations on lidar data using LAScatalog functionality. We visualize and inspect the data, validate the files, clip the data based on specific coordinates, generate a Canopy Height Model (CHM), specify processing options, and use parallel computing."
  },
  {
    "objectID": "05_engine.html#environment",
    "href": "05_engine.html#environment",
    "title": "LAScatalog",
    "section": "Environment",
    "text": "Environment\n\n# Clear environment\nrm(list = ls(globalenv()))\n\n# Load packages\nlibrary(lidR)\nlibrary(sf)"
  },
  {
    "objectID": "05_engine.html#basic-usage",
    "href": "05_engine.html#basic-usage",
    "title": "LAScatalog",
    "section": "Basic Usage",
    "text": "Basic Usage\nIn this section, we will cover the basic usage of the lidR package, including reading lidar data, visualization, and inspecting metadata.\nIf you haven’t downloaded the catalog files yet:\nDownload additional classified lidar files for 05_engine (.zip, 80 MB) Download additional normalized lidar files for 05_engine (.zip, 78 MB)\nUnzip ctg_class.zip and ctg_norm.zip to their respective folders in data/ctg_*\n\nRead catalog from directory of files\nWe begin by creating a LAS catalog (ctg) from a folder containing multiple .las/.laz files using the readLAScatalog() function.\n\n# Read catalog of files\nctg &lt;- readLAScatalog(folder = \"data/ctg_norm\")\n\n\n\nCatalog information\nWe can receive a summary about the catalog by calling the object’s name.\n\nctg\n#&gt; class       : LAScatalog (v1.1 format 1)\n#&gt; extent      : 2670500, 2672000, 1258500, 1260000 (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : CH1903+ / LV95 \n#&gt; area        : 2.25 km²\n#&gt; points      : 11.25 million points\n#&gt; type        : airborne\n#&gt; density     : 5 points/m²\n#&gt; density     : 2 pulses/m²\n#&gt; num. files  : 9\n\n\n\nVisualize catalog\nWe can visualize the catalog, showing the spatial coverage of the lidar data header extents. Note with chunk = TRUE we see the automatic buffers (dashed line) applied to each tile to avoid edge effects.\n\nplot(ctg, chunk = TRUE)\n\n\n\n\n\n\n\nFigure 1: Visualization of the LAScatalog showing the spatial layout of the individual lidar tiles.\n\n\n\n\n\nWith the mapview package installed, this map can be interactive if we use map = TRUE. Try clicking on a tile to see its header information.\n\n# Interactive\nplot(ctg, map = TRUE)\n\n\n\n\n\n\n\nFigure 2: Interactive visualization of the LAScatalog using mapview\n\n\n\n\n\nSuccessWarningError\n\n\nWhen all processing is completed without issues, all tiles are colored green.\n\n\n\nCatalog plot showing all tiles in green, indicating success.\n\n\n\n\nIf a process runs but generates a warning for a tile they are coloured yellow. The processing for that tile may have completed, but it requires inspection.\n\n\n\nCatalog plot tiles in orange, indicating warnings.\n\n\n\n\nA tile colored in red indicates that the processing failed for that file.\nTip: set opt_stop_early(ctg) &lt;- FALSE to continue processing\n\n\n\nCatalog plot showing some tiles in red, indicating errors."
  },
  {
    "objectID": "05_engine.html#file-indexing",
    "href": "05_engine.html#file-indexing",
    "title": "LAScatalog",
    "section": "File indexing",
    "text": "File indexing\nWe can explore indexing of LAScatalog input files for efficient processing.\nIndexing generates .lax files associated with each .laz/.las point cloud to speed up processing.\n\n\n\n\n\n\nIndexing\n\n\n\nThe lidR policy has always been: use LAStools and lasindex for spatial indexing. Alternatively there is a hidden function in lidR that users can call (lidR:::catalog_laxindex()).\n\n\n\n# check if files have .lax\nis.indexed(ctg)\n#&gt; [1] FALSE\n# generate index files\nlidR:::catalog_laxindex(ctg)\n\n\n\n\n\n\n\n#&gt; Chunk 1 of 9 (11.1%): state ✓\n#&gt; Chunk 2 of 9 (22.2%): state ✓\n#&gt; Chunk 3 of 9 (33.3%): state ✓\n#&gt; Chunk 4 of 9 (44.4%): state ✓\n#&gt; Chunk 5 of 9 (55.6%): state ✓\n#&gt; Chunk 6 of 9 (66.7%): state ✓\n#&gt; Chunk 7 of 9 (77.8%): state ✓\n#&gt; Chunk 8 of 9 (88.9%): state ✓\n#&gt; Chunk 9 of 9 (100%): state ✓\n# check if files have .lax\nis.indexed(ctg)\n#&gt; [1] TRUE"
  },
  {
    "objectID": "05_engine.html#generate-chm",
    "href": "05_engine.html#generate-chm",
    "title": "LAScatalog",
    "section": "Generate CHM",
    "text": "Generate CHM\nNow that we understand how a catalog works, lets apply it to generate some layers.\nFirst create another CHM by rasterizing the point cloud data from the catalog similarly to how we processed a single file.\n\n# Generate CHM\nchm &lt;- rasterize_canopy(las = ctg,\n                        res = 1,\n                        algorithm = p2r(subcircle = 0.15))\n#&gt; Chunk 1 of 9 (11.1%): state ✓\n#&gt; \n                                                                                \nChunk 2 of 9 (22.2%): state ✓\n#&gt; \n                                                                                \nChunk 3 of 9 (33.3%): state ✓\n#&gt; \n                                                                                \nChunk 4 of 9 (44.4%): state ✓\n#&gt; \n                                                                                \nChunk 5 of 9 (55.6%): state ✓\n#&gt; \n                                                                                \nChunk 6 of 9 (66.7%): state ✓\n#&gt; \n                                                                                \nChunk 7 of 9 (77.8%): state ✓\n#&gt; \n                                                                                \nChunk 8 of 9 (88.9%): state ✓\n#&gt; \n                                                                                \nChunk 9 of 9 (100%): state ✓\n#&gt; \n                                                                                \nplot(chm)\n\n\n\n\n\n\n\nFigure 3: Canopy Height Model (CHM) generated from the entire LAScatalog at 1.0m resolution.\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Canopy Height Model (CHM) generated from the entire LAScatalog at 1.0m resolution."
  },
  {
    "objectID": "05_engine.html#catalog-processing-options",
    "href": "05_engine.html#catalog-processing-options",
    "title": "LAScatalog",
    "section": "Catalog processing options",
    "text": "Catalog processing options\nWe can manipulate catalog options to alter processing on-the-fly across all tiles.\n\n# Setting options and re-rasterizing the CHM\nopt_filter(ctg) &lt;- \"-drop_z_below 0 -drop_z_above 50\"\nopt_select(ctg) &lt;- \"xyz\"\nchm &lt;- rasterize_canopy(las = ctg, res = 1, algorithm = p2r(subcircle = 0.15))\n#&gt; Chunk 1 of 9 (11.1%): state ✓\n#&gt; \n                                                                                \nChunk 2 of 9 (22.2%): state ✓\n#&gt; \n                                                                                \nChunk 3 of 9 (33.3%): state ✓\n#&gt; \n                                                                                \nChunk 4 of 9 (44.4%): state ✓\n#&gt; \n                                                                                \nChunk 5 of 9 (55.6%): state ✓\n#&gt; \n                                                                                \nChunk 6 of 9 (66.7%): state ✓\n#&gt; \n                                                                                \nChunk 7 of 9 (77.8%): state ✓\n#&gt; \n                                                                                \nChunk 8 of 9 (88.9%): state ✓\n#&gt; \n                                                                                \nChunk 9 of 9 (100%): state ✓\n#&gt; \n                                                                                \nplot(chm)\n\n\n\n\n\n\n\nFigure 5: CHM generated from the LAScatalog after applying filters to drop points below 0m and above 50m.\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: CHM generated from the LAScatalog after applying filters to drop points below 0m and above 50m."
  },
  {
    "objectID": "05_engine.html#generate-pixel-metrics-and-visualize",
    "href": "05_engine.html#generate-pixel-metrics-and-visualize",
    "title": "LAScatalog",
    "section": "Generate pixel metrics and visualize",
    "text": "Generate pixel metrics and visualize\nWe calculate summary metric rasters using the pixel_metrics function and visualize the results.\n\n# Generate pixel-based metrics\nmax_z &lt;- pixel_metrics(las = ctg, func = ~mean(Z), res = 20)\n#&gt; Chunk 1 of 9 (11.1%): state ✓\n#&gt; \n                                                                                \nChunk 2 of 9 (22.2%): state ✓\n#&gt; \n                                                                                \nChunk 3 of 9 (33.3%): state ✓\n#&gt; \n                                                                                \nChunk 4 of 9 (44.4%): state ✓\n#&gt; \n                                                                                \nChunk 5 of 9 (55.6%): state ✓\n#&gt; \n                                                                                \nChunk 6 of 9 (66.7%): state ✓\n#&gt; \n                                                                                \nChunk 7 of 9 (77.8%): state ✓\n#&gt; \n                                                                                \nChunk 8 of 9 (88.9%): state ✓\n#&gt; \n                                                                                \nChunk 9 of 9 (100%): state ✓\n#&gt; \n                                                                                \nplot(max_z)\n\n\n\n\n\n\n\nFigure 7: Raster of mean point height (Z) calculated from the LAScatalog at a 20m resolution.\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Raster of mean point height (Z) calculated from the LAScatalog at a 20m resolution."
  },
  {
    "objectID": "05_engine.html#first-returns-only",
    "href": "05_engine.html#first-returns-only",
    "title": "LAScatalog",
    "section": "First returns only",
    "text": "First returns only\nWe can adjust the catalog options to calculate metrics based on first returns only.\n\nopt_filter(ctg) &lt;- \"-drop_z_below 0 -drop_z_above 50 -keep_first\"\nmax_z &lt;- pixel_metrics(las = ctg, func = ~mean(Z), res = 20)\n#&gt; Chunk 1 of 9 (11.1%): state ✓\n#&gt; \n                                                                                \nChunk 2 of 9 (22.2%): state ✓\n#&gt; \n                                                                                \nChunk 3 of 9 (33.3%): state ✓\n#&gt; \n                                                                                \nChunk 4 of 9 (44.4%): state ✓\n#&gt; \n                                                                                \nChunk 5 of 9 (55.6%): state ✓\n#&gt; \n                                                                                \nChunk 6 of 9 (66.7%): state ✓\n#&gt; \n                                                                                \nChunk 7 of 9 (77.8%): state ✓\n#&gt; \n                                                                                \nChunk 8 of 9 (88.9%): state ✓\n#&gt; \n[==&gt;                                               ] 5% ETA: 39s     \n                                                                                \nChunk 9 of 9 (100%): state ✓\n#&gt; \n                                                                                \nplot(max_z)\n\n\n\n\n\n\n\nFigure 9: Raster of mean point height (Z) using only first returns, calculated from the LAScatalog at 20m resolution.\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: Raster of mean point height (Z) using only first returns, calculated from the LAScatalog at 20m resolution."
  },
  {
    "objectID": "05_engine.html#specifying-catalog-options",
    "href": "05_engine.html#specifying-catalog-options",
    "title": "LAScatalog",
    "section": "Specifying catalog options",
    "text": "Specifying catalog options\nWe can define how the LAScatalog should be broken down into chunks for processing. A 10m buffer is added to each chunk to avoid edge artifacts when a function’s calculations depend on neighboring points (also automatically applied by default).\n\n# Specify options\nopt_select(ctg) &lt;- \"xyz\"\nopt_chunk_size(ctg) &lt;- 500\nopt_chunk_buffer(ctg) &lt;- 10\nopt_progress(ctg) &lt;- TRUE\n\n# Visualize and summarize the catalog chunks\nplot(ctg, chunk = TRUE)\nsummary(ctg)\n#&gt; class       : LAScatalog (v1.1 format 1)\n#&gt; extent      : 2670500, 2672000, 1258500, 1260000 (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : CH1903+ / LV95 \n#&gt; area        : 2.25 km²\n#&gt; points      : 11.25 million points\n#&gt; type        : airborne\n#&gt; density     : 5 points/m²\n#&gt; density     : 2 pulses/m²\n#&gt; num. files  : 9 \n#&gt; proc. opt.  : buffer: 10 | chunk: 500\n#&gt; input opt.  : select: xyz | filter: -drop_z_below 0 -drop_z_above 50 -keep_first\n#&gt; output opt. : in memory | w2w guaranteed | merging enabled\n#&gt; drivers     :\n#&gt;  - Raster : format = GTiff  NAflag = -999999  \n#&gt;  - stars : NA_value = -999999  \n#&gt;  - Spatial : overwrite = FALSE  \n#&gt;  - SpatRaster : overwrite = FALSE  NAflag = -999999  \n#&gt;  - SpatVector : overwrite = FALSE  \n#&gt;  - LAS : no parameter\n#&gt;  - sf : quiet = TRUE  \n#&gt;  - data.frame : no parameter\n\n\n\n\n\n\n\nFigure 11: Visualization of the LAScatalog processing chunks, with a size of 500m (red solid lines) and a 10m buffer (green dashed lines).\n\n\n\n\n\n\nParallel computing\nIn this section, we explore parallel computing using the lidR package.\nParallel computing can apply the\n\n\n\n\n\n\nNote\n\n\n\nResource Considerations for Parallel Processing:\nBe mindful of your system’s resources. Parallel processing loads multiple tiles into memory (RAM) simultaneously. The required memory depends on the number of workers (cores), the point density and size of your tiles, and the complexity of the function being applied. If you encounter memory-related errors, try reducing the number of workers.\nRun parallel::detectCores() to see avaliable workers - limit your use to a fraction of available cores as other processes on your machine require computation."
  },
  {
    "objectID": "05_engine.html#load-future-library",
    "href": "05_engine.html#load-future-library",
    "title": "LAScatalog",
    "section": "Load future library",
    "text": "Load future library\nFirstly, we load the future library to enable parallel processing.\n\nlibrary(future)"
  },
  {
    "objectID": "05_engine.html#single-core-processing",
    "href": "05_engine.html#single-core-processing",
    "title": "LAScatalog",
    "section": "Single core processing",
    "text": "Single core processing\nTo establish a baseline, we generate a point density raster using a single processing core.\nplan(sequential) from future ensures that the code runs sequentially, not in parallel.\n\n# Process on single core\nplan(sequential)\n\n# Generate a point density raster (points per square metre)\ndens_seq &lt;- rasterize_density(ctg, res = 10)\n#&gt; Chunk 1 of 9 (11.1%): state ✓\n#&gt; \n                                                                                \nChunk 2 of 9 (22.2%): state ✓\n#&gt; \n                                                                                \nChunk 3 of 9 (33.3%): state ✓\n#&gt; \n                                                                                \nChunk 4 of 9 (44.4%): state ✓\n#&gt; \n                                                                                \nChunk 5 of 9 (55.6%): state ✓\n#&gt; \n                                                                                \nChunk 6 of 9 (66.7%): state ✓\n#&gt; \n[==&gt;                                               ] 5% ETA: 34s     \n                                                                                \nChunk 7 of 9 (77.8%): state ✓\n#&gt; \n                                                                                \nChunk 8 of 9 (88.9%): state ✓\n#&gt; \n                                                                                \nChunk 9 of 9 (100%): state ✓\n#&gt; \n                                                                                \n\n\nplot(dens_seq)\n\n\n\n\n\n\n\nFigure 12: Point density raster generated using a single processing core.\n\n\n\n\n\n\n\n\n\n\n\nFigure 13: Point density raster generated using a single processing core."
  },
  {
    "objectID": "05_engine.html#parallel-processing",
    "href": "05_engine.html#parallel-processing",
    "title": "LAScatalog",
    "section": "Parallel processing",
    "text": "Parallel processing\nNow, we’ll perform the same operation but leverage multiple cores.\nIn calling plan(multisession, workers = 3L) from future, lidR will automatically distribute the processing chunks across three CPU cores (workers).\nThe result should be identical to the single-core version, and should be faster than single-core systems.\n\n# Process on multi-core with three workers\nplan(multisession, workers = 3L)\n\n# Generate the same density raster, but in parallel\ndens_par &lt;- rasterize_density(ctg, res = 10)\n#&gt; Chunk 1 of 9 (11.1%): state ✓\n#&gt; \n                                                                                \nChunk 2 of 9 (22.2%): state ✓\n#&gt; \n                                                                                \nChunk 3 of 9 (33.3%): state ✓\n#&gt; \n                                                                                \nChunk 4 of 9 (44.4%): state ✓\n#&gt; \n                                                                                \nChunk 5 of 9 (55.6%): state ✓\n#&gt; \n                                                                                \nChunk 6 of 9 (66.7%): state ✓\n#&gt; \n                                                                                \nChunk 7 of 9 (77.8%): state ✓\n#&gt; \n                                                                                \nChunk 8 of 9 (88.9%): state ✓\n#&gt; \n                                                                                \nChunk 9 of 9 (100%): state ✓\n#&gt; \n                                                                                \n\nplot(dens_par)\n\n\n\n\n\n\n\nFigure 14: Point density raster generated in parallel using multiple cores.\n\n\n\n\n\n\n\n\n\n\n\nFigure 15: Point density raster generated in parallel using multiple cores."
  },
  {
    "objectID": "05_engine.html#revert-to-single-core",
    "href": "05_engine.html#revert-to-single-core",
    "title": "LAScatalog",
    "section": "Revert to single core",
    "text": "Revert to single core\nIt is good practice to always return the plan(sequential) after a parallel task is complete to avoid unintended parallel execution in later code.\n\n# Back to single core\nplan(sequential)"
  },
  {
    "objectID": "05_engine.html#conclusion",
    "href": "05_engine.html#conclusion",
    "title": "LAScatalog",
    "section": "Conclusion",
    "text": "Conclusion\nThis concludes the tutorial on basic usage, catalog validation, indexing, CHM generation, metric generation, and parallel computing to generate point density rasters using the lidR and future packages in R."
  },
  {
    "objectID": "05_engine.html#exercises",
    "href": "05_engine.html#exercises",
    "title": "LAScatalog",
    "section": "Exercises",
    "text": "Exercises\nUsing:\nctg &lt;- readLAScatalog(folder = \"data/ctg_norm\")\n\nE1.\nCalculate a set of metrics from the lidRmetrics package on the catalogue (voxel metrics will take too long)\nUsing:\nctg &lt;- readLAScatalog(folder = \"data/ctg_class\")\n\n\nE2.\nRead in the non-normalized las catalog filtering the point cloud to only include first returns.\n\n\nE3.\nGenerate a DTM at 1m spatial resolution for the provided catalog with only first returns.\n\n\n\n\n\n\nTip\n\n\n\nThe Multiple Returns and Canopy Penetration This exercise highlights a critical and unique capability of Airborne Laser Scanning (ALS).\nUnlike methods based on imagery like Digital Aerial Photogrammetry (DAP), map the visible surface, lidar pulses can penetrate through gaps in the vegetation generating multiple returns each. This allows us to map the ground surface even under dense forest cover, which is essential for creating accurate Digital Terrain Models (DTMs)."
  },
  {
    "objectID": "LPS_lidR_LiDAR_Intro.html",
    "href": "LPS_lidR_LiDAR_Intro.html",
    "title": "lidR: (A workshop for) Airborne lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "",
    "text": "Light Detection and Ranging (lidar)\nThe lidR package - a brief introduction\nWorkshop overview"
  },
  {
    "objectID": "LPS_lidR_LiDAR_Intro.html#overview",
    "href": "LPS_lidR_LiDAR_Intro.html#overview",
    "title": "lidR: (A workshop for) Airborne lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "Overview",
    "text": "Overview\n\nLight Detection and Ranging (lidar)\nThe lidR package - a brief introduction\nWorkshop overview"
  },
  {
    "objectID": "LPS_lidR_LiDAR_Intro.html#what-is-lidar",
    "href": "LPS_lidR_LiDAR_Intro.html#what-is-lidar",
    "title": "lidR: (A workshop for) Airborne lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "What is lidar?",
    "text": "What is lidar?\n\nLight Detection and Ranging\nActive form of remote sensing\nMeasures distance to target surfaces with millions of narrow light pulses\nAirborne laser scanning performs lidar systematically from aircraft or drones"
  },
  {
    "objectID": "LPS_lidR_LiDAR_Intro.html#lidar-data-point-clouds",
    "href": "LPS_lidR_LiDAR_Intro.html#lidar-data-point-clouds",
    "title": "lidR: (A workshop for) Airborne lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "Lidar Data – Point Clouds",
    "text": "Lidar Data – Point Clouds\n\n\n\nDiscrete returns are aggregated into point clouds (.LAS/.LAZ)\n\nLidar points have three-dimensional (XYZ) coordinates, and other attributes (Intensity, ReturnNumber, etc…)\n\nPoint clouds can be processed into vegetation structure summaries with lidR\n\n\n\n\n\nAs with many remote sensing data analyses tasks we are seeking to produce information from simplification to pull a signal of interest (in this case variability in vegetation structure) out of our dataset (a dense point cloud of three-dimensional coordinates that characterize the vegetation)\nTo do so we often generate summary metrics that act similarly to spectral indices in passive optical remote sensing, they ratio or generate statistics on the distribution of points (max, mean height, canopy cover, percentiles, leaf-area density profiles)"
  },
  {
    "objectID": "LPS_lidR_LiDAR_Intro.html#lidr",
    "href": "LPS_lidR_LiDAR_Intro.html#lidr",
    "title": "lidR: (A workshop for) Airborne lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "lidR",
    "text": "lidR\n\n\n\nWritten by Jean-Romain Roussel\n\nPackage for manipulating and visualizing ALS data\n\nWritten entirely open source within R-geospatial ecosystem (terra/sf)\n\nMost processes run efficiently with back-end C++ code"
  },
  {
    "objectID": "LPS_lidR_LiDAR_Intro.html#r-lidar",
    "href": "LPS_lidR_LiDAR_Intro.html#r-lidar",
    "title": "lidR: (A workshop for) Airborne lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "r-lidar",
    "text": "r-lidar\n\n\n\nlidR author Jean-Romain Roussel is commited to maintaining the lidR package as fully open source\nHe now does so through a r-lidar as consulting and development company targeted at lidar related applications\nVisit r-lidar.com or contact info@r-lidar.com for more information"
  },
  {
    "objectID": "LPS_lidR_LiDAR_Intro.html#workshop-outline",
    "href": "LPS_lidR_LiDAR_Intro.html#workshop-outline",
    "title": "lidR: (A workshop for) Airborne lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "Workshop Outline",
    "text": "Workshop Outline\n\nIntroduction to lidar and lidR (09:00)\nReading LAS and LAZ files (09:10)\nPoint Classification and filtering (9:15)\nDigital Terrain Models and Height Normalization (9:25)\nCanopy Height Models (9:35)\nlidar Summary Metrics (9:50)\nFile Collection Processing Engine (10:10)"
  },
  {
    "objectID": "LPS_lidR_LiDAR_Intro.html#get-set-up",
    "href": "LPS_lidR_LiDAR_Intro.html#get-set-up",
    "title": "lidR: (A workshop for) Airborne lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "Get Set Up!",
    "text": "Get Set Up!\nhttps://liamirwin.github.io/LPS_lidRtutorial/"
  },
  {
    "objectID": "supplemental/S1_roi.html",
    "href": "supplemental/S1_roi.html",
    "title": "Regions of Interest",
    "section": "",
    "text": "Code\nlidRbook section"
  },
  {
    "objectID": "supplemental/S1_roi.html#relevant-resources",
    "href": "supplemental/S1_roi.html#relevant-resources",
    "title": "Regions of Interest",
    "section": "",
    "text": "Code\nlidRbook section"
  },
  {
    "objectID": "supplemental/S1_roi.html#overview",
    "href": "supplemental/S1_roi.html#overview",
    "title": "Regions of Interest",
    "section": "Overview",
    "text": "Overview\nWe demonstrate the selection of regions of interest (ROIs) from LiDAR data. Geometries like circles and rectangles are selected based on coordinates. Complex geometries are extracted from shapefiles to clip specific areas."
  },
  {
    "objectID": "supplemental/S1_roi.html#environment",
    "href": "supplemental/S1_roi.html#environment",
    "title": "Regions of Interest",
    "section": "Environment",
    "text": "Environment\n\n# Clear environment\nrm(list = ls(globalenv()))\n\n# Load packages\nlibrary(lidR)\nlibrary(sf)"
  },
  {
    "objectID": "supplemental/S1_roi.html#simple-geometries",
    "href": "supplemental/S1_roi.html#simple-geometries",
    "title": "Regions of Interest",
    "section": "Simple Geometries",
    "text": "Simple Geometries\n\nLoad LiDAR Data and Inspect\nWe start by loading some LiDAR data and inspecting its header and number of point records.\n\nlas &lt;- readLAS(files = 'data/zrh_norm.laz')\n# Inspect the header and the number of point records\nlas@header\n\nFile signature:           LASF \nFile source ID:           0 \nGlobal encoding:\n - GPS Time Type: GPS Week Time \n - Synthetic Return Numbers: no \n - Well Know Text: CRS is GeoTIFF \n - Aggregate Model: false \nProject ID - GUID:        00000000-0000-0000-5053-004d00000000 \nVersion:                  1.1\nSystem identifier:         \nGenerating software:      rlas R package \nFile creation d/y:        0/0\nheader size:              227 \nOffset to point data:     305 \nNum. var. length record:  1 \nPoint data format:        1 \nPoint data record length: 28 \nNum. of point records:    1270080 \nNum. of points by return: 471651 342346 241371 135987 56797 \nScale factor X Y Z:       0.01 0.01 0.01 \nOffset X Y Z:             0 0 0 \nmin X Y Z:                2670505 1258734 -0.88 \nmax X Y Z:                2670755 1258984 48.31 \nVariable Length Records (VLR):\n   Variable Length Record 1 of 1 \n       Description: by LAStools of rapidlasso GmbH \n       Tags:\n          Key 1024 value 1 \n          Key 3072 value 2056 \nExtended Variable Length Records (EVLR):  void\n\nlas@header$`Number of point records`\n\n[1] 1270080\n\n\n\n\nSelect Circular and Rectangular Areas\nWe can select circular and rectangular areas from the LiDAR data based on specified coordinates and radii or dimensions.\n\n# Establish coordinates\nx &lt;- 2670592\ny &lt;- 1258890\n\n# Select a circular area\ncircle &lt;- clip_circle(las = las, xcenter = x, ycenter = y, radius = 30)\n\n# Inspect the circular area and the number of point records\ncircle\n\nclass        : LAS (v1.1 format 1)\nmemory       : 3.1 Mb \nextent       : 2670562, 2670622, 1258860, 1258920 (xmin, xmax, ymin, ymax)\ncoord. ref.  : CH1903+ / LV95 \narea         : 2903 m²\npoints       : 58.4 thousand points\ntype         : airborne\ndensity      : 20.13 points/m²\ndensity      : 7.55 pulses/m²\n\ncircle@header$`Number of point records`\n\n[1] 58447\n\n\n# Plot the circular area\nplot(circle)\nWe can do the same with a rectangular area by defining corner coordinates.\n\n# Select a rectangular area\nrect &lt;- clip_rectangle(las = las, xleft = x, ybottom = y, xright = x + 40, ytop = y + 30)\n\n# Plot the rectangular area\nplot(rect)\nWe can also supply multiple coordinate pairs to clip multiple ROIs.\n\n# Select multiple random circular areas\nx &lt;- runif(2, x, x)\ny &lt;- runif(2, 1258840, 1258890)\n\nplots &lt;- clip_circle(las = las, xcenter = x, ycenter = y, radius = 10)\n\n# Plot each of the multiple circular areas\nplot(plots[[1]])\n# Plot each of the multiple circular areas\nplot(plots[[2]])"
  },
  {
    "objectID": "supplemental/S1_roi.html#extraction-of-complex-geometries-from-shapefiles",
    "href": "supplemental/S1_roi.html#extraction-of-complex-geometries-from-shapefiles",
    "title": "Regions of Interest",
    "section": "Extraction of Complex Geometries from Shapefiles",
    "text": "Extraction of Complex Geometries from Shapefiles\nWe demonstrate how to extract complex geometries from shapefiles using the clip_roi() function from the lidR package.\nWe use the sf package to load an ROI and then clip to its extents.\n\n# Load the shapefile using sf\nstand_bdy &lt;- sf::st_read(dsn = \"data/roi/roi.gpkg\", quiet = TRUE)\n\n# Plot the LiDAR header information without the map\nplot(las@header, map = FALSE)\n\n# Plot the stand boundary areas on top of the LiDAR header plot\nplot(stand_bdy, add = TRUE, col = \"#08B5FF39\")\n\n\n\n\n\n\n\n# Extract points within the stand boundary using clip_roi()\nstand &lt;- clip_roi(las = las, geometry = stand_bdy)\n\n# Plot the extracted points within the planting areas\nplot(stand)"
  },
  {
    "objectID": "supplemental/S1_roi.html#clipping-rois-with-a-catalog",
    "href": "supplemental/S1_roi.html#clipping-rois-with-a-catalog",
    "title": "Regions of Interest",
    "section": "Clipping ROIs with a catalog",
    "text": "Clipping ROIs with a catalog\nWe clip the LAS data in the catalog using specified coordinate groups.\n\nctg &lt;- catalog(\"data/ctg_norm\")\n\n# Set coordinate groups\nx &lt;- c(2670578, 2671234, 2671499, 2671755, 2671122)\ny &lt;- c(1258601, 1259050, 1259450, 1259900, 1258750)\n\n# Visualize coordinate groups\nplot(ctg)\npoints(x, y)\n\n\n\n\n\n\n\n# Clip plots\nrois &lt;- clip_circle(las = ctg, xcenter = x, ycenter = y, radius = 30)\n\nplot(rois[[1]])\nplot(rois[[3]])"
  },
  {
    "objectID": "supplemental/S1_roi.html#validate-clipped-data",
    "href": "supplemental/S1_roi.html#validate-clipped-data",
    "title": "Regions of Interest",
    "section": "Validate clipped data",
    "text": "Validate clipped data\nWe validate the clipped LAS data using the las_check function.\n\nlas_check(rois[[1]])\n\n\n Checking the data\n  - Checking coordinates... ✓\n  - Checking coordinates type... ✓\n  - Checking coordinates range... ✓\n  - Checking coordinates quantization... ✓\n  - Checking attributes type... ✓\n  - Checking ReturnNumber validity... ✓\n  - Checking NumberOfReturns validity... ✓\n  - Checking ReturnNumber vs. NumberOfReturns... ✓\n  - Checking RGB validity... ✓\n  - Checking absence of NAs... ✓\n  - Checking duplicated points... ✓\n  - Checking degenerated ground points... ✓\n  - Checking attribute population...\n    🛈 'ScanDirectionFlag' attribute is not populated\n    🛈 'EdgeOfFlightline' attribute is not populated\n  - Checking gpstime incoherances ✓\n  - Checking flag attributes... ✓\n  - Checking user data attribute... ✓\n Checking the header\n  - Checking header completeness... ✓\n  - Checking scale factor validity... ✓\n  - Checking point data format ID validity... ✓\n  - Checking extra bytes attributes validity... ✓\n  - Checking the bounding box validity... ✓\n  - Checking coordinate reference system... ✓\n Checking header vs data adequacy\n  - Checking attributes vs. point format... ✓\n  - Checking header bbox vs. actual content... ✓\n  - Checking header number of points vs. actual content... ✓\n  - Checking header return number vs. actual content... ✓\n Checking coordinate reference system...\n  - Checking if the CRS was understood by R... ✓\n Checking preprocessing already done \n  - Checking ground classification... yes\n  - Checking normalization... yes\n  - Checking negative outliers...\n    ⚠ 6 points below 0\n  - Checking flightline classification... yes\n Checking compression\n  - Checking attribute compression...\n   -  ScanDirectionFlag is compressed\n   -  EdgeOfFlightline is compressed\n   -  Synthetic_flag is compressed\n   -  Keypoint_flag is compressed\n   -  Withheld_flag is compressed\n   -  UserData is compressed\n\nlas_check(rois[[3]])\n\n\n Checking the data\n  - Checking coordinates... ✓\n  - Checking coordinates type... ✓\n  - Checking coordinates range... ✓\n  - Checking coordinates quantization... ✓\n  - Checking attributes type... ✓\n  - Checking ReturnNumber validity... ✓\n  - Checking NumberOfReturns validity... ✓\n  - Checking ReturnNumber vs. NumberOfReturns... ✓\n  - Checking RGB validity... ✓\n  - Checking absence of NAs... ✓\n  - Checking duplicated points... ✓\n  - Checking degenerated ground points... ✓\n  - Checking attribute population...\n    🛈 'ScanDirectionFlag' attribute is not populated\n    🛈 'EdgeOfFlightline' attribute is not populated\n  - Checking gpstime incoherances\n    ✗ 5 pulses (points with the same gpstime) have points with identical ReturnNumber\n  - Checking flag attributes... ✓\n  - Checking user data attribute... ✓\n Checking the header\n  - Checking header completeness... ✓\n  - Checking scale factor validity... ✓\n  - Checking point data format ID validity... ✓\n  - Checking extra bytes attributes validity... ✓\n  - Checking the bounding box validity... ✓\n  - Checking coordinate reference system... ✓\n Checking header vs data adequacy\n  - Checking attributes vs. point format... ✓\n  - Checking header bbox vs. actual content... ✓\n  - Checking header number of points vs. actual content... ✓\n  - Checking header return number vs. actual content... ✓\n Checking coordinate reference system...\n  - Checking if the CRS was understood by R... ✓\n Checking preprocessing already done \n  - Checking ground classification... yes\n  - Checking normalization... yes\n  - Checking negative outliers...\n    ⚠ 5 points below 0\n  - Checking flightline classification... yes\n Checking compression\n  - Checking attribute compression...\n   -  ScanDirectionFlag is compressed\n   -  EdgeOfFlightline is compressed\n   -  Synthetic_flag is compressed\n   -  Keypoint_flag is compressed\n   -  Withheld_flag is compressed\n   -  UserData is compressed"
  },
  {
    "objectID": "supplemental/S1_roi.html#independent-files-e.g.-plots-as-catalogs",
    "href": "supplemental/S1_roi.html#independent-files-e.g.-plots-as-catalogs",
    "title": "Regions of Interest",
    "section": "Independent files (e.g. plots) as catalogs",
    "text": "Independent files (e.g. plots) as catalogs\nWe read an individual LAS file as a catalog and perform operations on it.\n\n# Read single file as catalog\nctg &lt;- readLAScatalog(folder = \"data/zrh_norm.laz\")\n\n# Set options for output files\nopt_output_files(ctg) &lt;- paste0(tempdir(),\"/{XCENTER}_{XCENTER}\")\n\n# Write file as .laz\nopt_laz_compression(ctg) &lt;- TRUE\n\n# Get random plot locations and clip\nx &lt;- runif(n = 4, min = ctg$Min.X, max = ctg$Max.X)\ny &lt;- runif(n = 4, min = ctg$Min.Y, max = ctg$Max.Y)\nrois &lt;- clip_circle(las = ctg, xcenter = x, ycenter = y, radius = 10)\n\n\n\n\n\n\n\n\nChunk 1 of 4 (25%): state ✓\n\n                                                                                \nChunk 2 of 4 (50%): state ✓\n\n                                                                                \nChunk 3 of 4 (75%): state ✓\n\n                                                                                \nChunk 4 of 4 (100%): state ✓\n\n                                                                                \n\n\n\n# Read catalog of plots\nctg_plots &lt;- readLAScatalog(tempdir())\n\n# Set independent files option\nopt_independent_files(ctg_plots) &lt;- TRUE\nopt_output_files(ctg_plots) &lt;- paste0(tempdir(),\"/{XCENTER}_{XCENTER}\")\n\n# Generate plot-level terrain models\nrasterize_terrain(las = ctg_plots, res = 1, algorithm = tin())\n\n\n\n\n\n\n\n\nChunk 1 of 4 (25%): state ✓\n\n                                                                                \nChunk 2 of 4 (50%): state ✓\n\n                                                                                \nChunk 3 of 4 (75%): state ✓\n\n                                                                                \nChunk 4 of 4 (100%): state ✓\n\n                                                                                \n\n\nclass       : SpatRaster \ndimensions  : 193, 205, 1  (nrow, ncol, nlyr)\nresolution  : 1, 1  (x, y)\nextent      : 2670539, 2670744, 1258791, 1258984  (xmin, xmax, ymin, ymax)\ncoord. ref. : CH1903+ / LV95 (EPSG:2056) \nsource      : rasterize_terrain.vrt \nname        : Z \nmin value   : 0 \nmax value   : 0 \n\n\n\n# Check files\npath &lt;- paste0(tempdir())\nfile_list &lt;- list.files(path, full.names = TRUE)\nfile &lt;- file_list[grep(\"\\\\.tif$\", file_list)][[1]]\n\n# plot dtm\nplot(terra::rast(file))"
  },
  {
    "objectID": "supplemental/S1_roi.html#conclusion",
    "href": "supplemental/S1_roi.html#conclusion",
    "title": "Regions of Interest",
    "section": "Conclusion",
    "text": "Conclusion\nThis concludes our tutorial on selecting simple geometries and extracting complex geometries from geopackage files (or shapefiles etc…) using the lidR package in R."
  },
  {
    "objectID": "LPS_lidR_LiDAR_Intro.html#presenters",
    "href": "LPS_lidR_LiDAR_Intro.html#presenters",
    "title": "lidR: (A workshop for) Airborne lidar Data Manipulation and Visualization for Environmental Applications",
    "section": "Presenters",
    "text": "Presenters\nLiam Irwin - PhD Student Brent Murray - PhD Student Nicholas Coops - Professor\nIntegrated Remote Sensing Studio University of British Columbia Vancouver, Canada"
  }
]